<!DOCTYPE HTML>
<html>

<head>
  <meta name="google-site-verification" content="6-Grm86DHfS67XSHMuvfO8cIcQcOWPpjGvOBMxbA3Fo" />
  <meta charset="utf-8">
  
  <title>Initialization in DL | WatsonYang&#39;s Blog</title>
  
  <meta name="author" content="Watson Yang">
  
  <meta name="description" content="My secret private space.">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:title" content="Initialization in DL" />
  <meta property="og:site_name" content="WatsonYang&#39;s Blog" />

  
  <meta property="og:image" content="" />
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml"
    title="WatsonYang&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  


  <a href="https://github.com/watsonyanghx" target="_blank">
    <img style="position: absolute; top: 0; left: 0; border: 0;"
      src="https://s3.amazonaws.com/github/ribbons/forkme_left_gray_6d6d6d.png" alt="Fork me on GitHub">
  </a>
  <script src="https://use.fontawesome.com/4eb261e456.js"></script>

  <script>
    MathJax = {
      tex: {
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>
<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">WatsonYang&#39;s Blog</a></h1>
  <h2><a href="/">Enrich yourself.</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/about">About</a></li>
    

    <li> <a href="/atom.xml">RSS</a> </li>
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2020-04-25T08:04:00.000Z"><a href="/2020/04/25/Initialization-in-DL/">2020-04-25</a></time>
      
      
  
    <h1 class="title">Initialization in DL</h1>
  

    </header>
    <div class="entry">
      
        <h2 id="Category"><a href="#Category" class="headerlink" title="Category"></a>Category</h2><h3 id="Lecun"><a href="#Lecun" class="headerlink" title="Lecun"></a>Lecun</h3><ul>
<li><p>Uniform</p>
<p>It draws samples from a uniform distribution within [-limit, limit] where limit is <code>limit = sqrt(3. / fan_in)</code>。</p>
<p><code>fan_in</code>: the number of input units in the weight tensor。</p>
<p>Tensorflow中的函数：</p>
<ul>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers/lecun_uniform" target="_blank" rel="noopener">tf.initializers.lecun_uniform</a></p>
<a id="more"></a>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/variance_scaling_initializer" target="_blank" rel="noopener">tf.variance_scaling_initializer</a></p>
</li>
</ul>
</li>
<li><p>Normal</p>
<p>It draws samples from a truncated normal distribution centered on 0 with <code>stddev = sqrt(1. / fan_in)</code>。</p>
<p><code>fan_in</code>: the number of input units in the weight tensor.</p>
<p>Tensorflow中的函数：</p>
<ul>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers/lecun_normal" target="_blank" rel="noopener">tf.initializers.lecun_normal</a></p>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/variance_scaling_initializer" target="_blank" rel="noopener">tf.variance_scaling_initializer</a></p>
</li>
</ul>
</li>
</ul>
<h3 id="Xavier-or-Glorot"><a href="#Xavier-or-Glorot" class="headerlink" title="Xavier (or Glorot)"></a>Xavier (or Glorot)</h3><ul>
<li><p>Uniform</p>
<p>It draws samples from a uniform distribution within [-limit, limit] where limit is <code>limit = sqrt(6. / (fan_in + fan_out))</code>。</p>
<p><code>fan_in</code>: the number of input units in the weight tensor.<br><code>fan_out</code>: the number of output units in the weight tensor.</p>
<p>Tensorflow中的函数：</p>
<ul>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/glorot_uniform_initializer" target="_blank" rel="noopener">tf.glorot_uniform_initializer</a></p>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/xavier_initializer" target="_blank" rel="noopener">tf.contrib.layers.xavier_initializer(uniform=True)</a></p>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/variance_scaling_initializer" target="_blank" rel="noopener">tf.contrib.layers.variance_scaling_initializer</a></p>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/variance_scaling_initializer" target="_blank" rel="noopener">tf.variance_scaling_initializer</a></p>
</li>
</ul>
</li>
<li><p>Normal</p>
<p>It draws samples from a truncated normal distribution centered on 0 with <code>stddev = sqrt(2. / (fan_in + fan_out))</code>。</p>
<p>Tensorflow中的函数：</p>
<ul>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/glorot_normal_initializer" target="_blank" rel="noopener">tf.glorot_normal_initializer</a></p>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/xavier_initializer" target="_blank" rel="noopener">tf.contrib.layers.xavier_initializer(uniform=False)</a></p>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/variance_scaling_initializer" target="_blank" rel="noopener">tf.contrib.layers.variance_scaling_initializer</a></p>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/variance_scaling_initializer" target="_blank" rel="noopener">tf.variance_scaling_initializer</a></p>
</li>
</ul>
</li>
</ul>
<h3 id="He-MSRA-initialization"><a href="#He-MSRA-initialization" class="headerlink" title="He / MSRA initialization"></a>He / MSRA initialization</h3><ul>
<li><p>Uniform</p>
<p>It draws samples from a uniform distribution within [-limit, limit] where limit is <code>limit = sqrt(6. / fan_in)</code>。</p>
<p><code>fan_in</code>: the number of input units in the weight tensor。</p>
<p>Tensorflow中的函数：</p>
<ul>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers/he_uniform" target="_blank" rel="noopener">tf.initializers.he_uniform</a></p>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/variance_scaling_initializer" target="_blank" rel="noopener">tf.variance_scaling_initializer</a></p>
</li>
</ul>
</li>
<li><p>Normal</p>
<p>It draws samples from a truncated normal distribution centered on 0 with <code>stddev = sqrt(2 / fan_in)</code>。</p>
<p><code>fan_in</code>: the number of input units in the weight tensor。</p>
<p>Tensorflow中的函数：</p>
<ul>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers/he_normal" target="_blank" rel="noopener">tf.initializers.he_normal</a></p>
</li>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/variance_scaling_initializer" target="_blank" rel="noopener">tf.variance_scaling_initializer</a></p>
</li>
</ul>
</li>
</ul>
<p>如果用了<code>Relu/Leaky Relu</code>最好用这个初始化方法。</p>
<h3 id="Glorot-He"><a href="#Glorot-He" class="headerlink" title="Glorot_He"></a>Glorot_He</h3><ul>
<li><p>Uniform</p>
</li>
<li><p>Normal</p>
</li>
</ul>
<h3 id="RandomUniform"><a href="#RandomUniform" class="headerlink" title="RandomUniform"></a>RandomUniform</h3><p>Tensorflow中的函数：</p>
<ul>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/random_uniform_initializer" target="_blank" rel="noopener">tf.random_uniform_initializer</a></li>
</ul>
<h3 id="TruncatedNormal"><a href="#TruncatedNormal" class="headerlink" title="TruncatedNormal"></a>TruncatedNormal</h3><p>Tensorflow中的函数：</p>
<ul>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/truncated_normal_initializer" target="_blank" rel="noopener">tf.truncated_normal_initializer</a></li>
</ul>
<h3 id="Orthogonal"><a href="#Orthogonal" class="headerlink" title="Orthogonal"></a>Orthogonal</h3><h2 id="Template-in-tensorflow"><a href="#Template-in-tensorflow" class="headerlink" title="Template in tensorflow"></a>Template in tensorflow</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_weights</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">uniform</span><span class="params">(stdev, size)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> _weights_stdev <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            stdev = _weights_stdev</span><br><span class="line">        <span class="keyword">return</span> np.random.uniform(</span><br><span class="line">            low=-stdev * np.sqrt(<span class="number">3</span>),</span><br><span class="line">            high=stdev * np.sqrt(<span class="number">3</span>),</span><br><span class="line">            size=size</span><br><span class="line">        ).astype(<span class="string">'float32'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># https://keras.io/initializers/</span></span><br><span class="line">    <span class="keyword">if</span> initialization == <span class="string">'lecun'</span>:  <span class="comment"># and input_dim != output_dim):</span></span><br><span class="line">        <span class="comment"># disabling orth. init for now because it's too slow</span></span><br><span class="line">        weight_values = uniform(</span><br><span class="line">            np.sqrt(<span class="number">1.</span> / input_dim),</span><br><span class="line">            (input_dim, output_dim)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># tf.contrib.layers.variance_scaling_initializer(</span></span><br><span class="line">        <span class="comment">#     factor=1.0,</span></span><br><span class="line">        <span class="comment">#     mode='FAN_IN',</span></span><br><span class="line">        <span class="comment">#     uniform=True,</span></span><br><span class="line">        <span class="comment">#     seed=None,</span></span><br><span class="line">        <span class="comment">#     dtype=tf.float32</span></span><br><span class="line">        <span class="comment"># )</span></span><br><span class="line">    <span class="keyword">elif</span> initialization == <span class="string">'glorot'</span> <span class="keyword">or</span> initialization == <span class="string">'xavier'</span> <span class="keyword">or</span> (initialization <span class="keyword">is</span> <span class="literal">None</span>):</span><br><span class="line">        weight_values = uniform(</span><br><span class="line">            np.sqrt(<span class="number">2.</span> / (input_dim + output_dim)),</span><br><span class="line">            (input_dim, output_dim)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># tf.contrib.layers.variance_scaling_initializer(</span></span><br><span class="line">        <span class="comment">#     factor=1.0,</span></span><br><span class="line">        <span class="comment">#     mode='FAN_AVG',</span></span><br><span class="line">        <span class="comment">#     uniform=True,</span></span><br><span class="line">        <span class="comment">#     seed=None,</span></span><br><span class="line">        <span class="comment">#     dtype=tf.float32</span></span><br><span class="line">        <span class="comment"># )</span></span><br><span class="line">    <span class="keyword">elif</span> initialization == <span class="string">'he'</span>:</span><br><span class="line">        weight_values = uniform(</span><br><span class="line">            np.sqrt(<span class="number">2.</span> / input_dim),</span><br><span class="line">            (input_dim, output_dim)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># tf.contrib.layers.variance_scaling_initializer(</span></span><br><span class="line">        <span class="comment">#     factor=2.0,</span></span><br><span class="line">        <span class="comment">#     mode='FAN_IN',</span></span><br><span class="line">        <span class="comment">#     uniform=True,</span></span><br><span class="line">        <span class="comment">#     seed=None,</span></span><br><span class="line">        <span class="comment">#     dtype=tf.float32</span></span><br><span class="line">        <span class="comment"># )</span></span><br><span class="line">    <span class="keyword">elif</span> initialization == <span class="string">'glorot_he'</span>:</span><br><span class="line">        weight_values = uniform(</span><br><span class="line">            np.sqrt(<span class="number">4.</span> / (input_dim + output_dim)),</span><br><span class="line">            (input_dim, output_dim)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># tf.contrib.layers.variance_scaling_initializer(</span></span><br><span class="line">        <span class="comment">#     factor=2.0,</span></span><br><span class="line">        <span class="comment">#     mode='FAN_AVG',</span></span><br><span class="line">        <span class="comment">#     uniform=True,</span></span><br><span class="line">        <span class="comment">#     seed=None,</span></span><br><span class="line">        <span class="comment">#     dtype=tf.float32</span></span><br><span class="line">        <span class="comment"># )</span></span><br><span class="line">    <span class="keyword">elif</span> initialization == <span class="string">'orthogonal'</span> <span class="keyword">or</span> \</span><br><span class="line">            (initialization <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> input_dim == output_dim):</span><br><span class="line">        <span class="comment"># From lasagne</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">sample</span><span class="params">(shape)</span>:</span></span><br><span class="line">            <span class="keyword">if</span> len(shape) &lt; <span class="number">2</span>:</span><br><span class="line">                <span class="keyword">raise</span> RuntimeError(<span class="string">"Only shapes of length 2 or more are "</span></span><br><span class="line">                                   <span class="string">"supported."</span>)</span><br><span class="line">            flat_shape = (shape[<span class="number">0</span>], np.prod(shape[<span class="number">1</span>:]))</span><br><span class="line">            <span class="comment"># <span class="doctag">TODO:</span> why normal and not uniform?</span></span><br><span class="line">            a = np.random.normal(<span class="number">0.0</span>, <span class="number">1.0</span>, flat_shape)</span><br><span class="line">            u, _, v = np.linalg.svd(a, full_matrices=<span class="literal">False</span>)</span><br><span class="line">            <span class="comment"># pick the one with the correct shape</span></span><br><span class="line">            q = u <span class="keyword">if</span> u.shape == flat_shape <span class="keyword">else</span> v</span><br><span class="line">            q = q.reshape(shape)</span><br><span class="line">            <span class="keyword">return</span> q.astype(<span class="string">'float32'</span>)</span><br><span class="line"></span><br><span class="line">        weight_values = sample((input_dim, output_dim))</span><br><span class="line">    <span class="keyword">elif</span> initialization[<span class="number">0</span>] == <span class="string">'uniform'</span>:</span><br><span class="line">        weight_values = np.random.uniform(</span><br><span class="line">            low=-initialization[<span class="number">1</span>],</span><br><span class="line">            high=initialization[<span class="number">1</span>],</span><br><span class="line">            size=(input_dim, output_dim)</span><br><span class="line">        ).astype(<span class="string">'float32'</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">'Invalid initialization!'</span>)</span><br><span class="line">    </span><br><span class="line">    weight = tf.get_variable(name=<span class="string">'W'</span>, dtype=tf.float32,</span><br><span class="line">                             initializer=weight_values)</span><br></pre></td></tr></table></figure>


<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul>
<li><p>为什么要打破网络的对称性。</p>
<p><code>对称性</code>是指某一个隐藏层中的所有hidden units都是一样的。如果网络是对称的，隐藏层相当于只有一个有意义的 hidden unit（只学到了一个特征）。而理想的情况是每一个hidden unit都学到了各自的特征，因此要打破网络的对称性。</p>
</li>
<li><p>为什么不能全初始化为0。</p>
<p>如果全部初始化为0，那么会使得网络变成对称的（此时没有考虑bias，没有使用dropout）。</p>
<p><a href="https://zhuanlan.zhihu.com/p/27190255" target="_blank" rel="noopener">为什么神经网络参数不能全部初始化为全0？</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/32063750" target="_blank" rel="noopener">关于神经网络参数初始化为全0的思考</a></p>
<p><a href="https://www.zhihu.com/question/265398015/answer/294725871" target="_blank" rel="noopener">为什么神经网络中从输入层到隐含层的权值必须互不相等？ - 知乎</a></p>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><p><a href="https://keras.io/initializers/" target="_blank" rel="noopener">Initializers - Keras Documentation</a></p>
</li>
<li><p><a href="https://www.google.com.hk/search?newwindow=1&safe=strict&hl=zh-CN&source=hp&ei=GHDXWpP5JMfivATs9KW4Cg&q=deep+learning+initialization&oq=deep+learning+init&gs_l=psy-ab.1.0.0l2j0i30k1j0i8i30k1l4.2642.17573.0.20665.23.16.0.4.4.0.550.2722.2-6j1j0j2.10.0....0...1c.1.64.psy-ab..10.11.1975.0..0i131k1.205.NkJOqz0wdv8" target="_blank" rel="noopener">deep learning initialization - Google 搜索</a></p>
</li>
<li><p><a href="https://cs231n.github.io/neural-networks-2/#init" target="_blank" rel="noopener">CS231n Convolutional Neural Networks for Visual Recognition</a></p>
</li>
</ul>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/Deep-Learning/">Deep Learning</a>
  </div>

        
        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">Comments</h1>

  
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript>
  </div>
  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:watsonyanghx.github.io">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">Categories</h3>
  <ul class="entry">
  
    <li><a href="/categories/Algorithm/">Algorithm</a><small>2</small></li>
  
    <li><a href="/categories/Computer-Vision/">Computer Vision</a><small>3</small></li>
  
    <li><a href="/categories/Deep-Learning/">Deep Learning</a><small>3</small></li>
  
    <li><a href="/categories/Interview/">Interview</a><small>1</small></li>
  
    <li><a href="/categories/Machine-Learning/">Machine Learning</a><small>8</small></li>
  
    <li><a href="/categories/Deep-Learning/Machine-Learning/">Machine Learning</a><small>1</small></li>
  
    <li><a href="/categories/NLP/">NLP</a><small>1</small></li>
  
    <li><a href="/categories/OJ/">OJ</a><small>48</small></li>
  
    <li><a href="/categories/Paper/">Paper</a><small>5</small></li>
  
    <li><a href="/categories/Reinforcement-Learning/">Reinforcement Learning</a><small>1</small></li>
  
    <li><a href="/categories/Technique-Summaries/">Technique Summaries</a><small>2</small></li>
  
    <li><a href="/categories/Tools/">Tools</a><small>1</small></li>
  
    <li><a href="/categories/WhatEver/">WhatEver</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">Tag Cloud</h3>
  <div class="entry">
    <a href="/tags/Algorithm/" style="font-size: 18.18px;">Algorithm</a> <a href="/tags/BFS/" style="font-size: 11.82px;">BFS</a> <a href="/tags/Backtracking/" style="font-size: 12.73px;">Backtracking</a> <a href="/tags/Binary-Tree/" style="font-size: 14.55px;">Binary Tree</a> <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/CNN/" style="font-size: 15.45px;">CNN</a> <a href="/tags/CS231n/" style="font-size: 11.82px;">CS231n</a> <a href="/tags/Combinatorial-number/" style="font-size: 10.91px;">Combinatorial number</a> <a href="/tags/DFS/" style="font-size: 14.55px;">DFS</a> <a href="/tags/DP/" style="font-size: 19.09px;">DP</a> <a href="/tags/Data-structure/" style="font-size: 10.91px;">Data structure</a> <a href="/tags/DeconvNet/" style="font-size: 10px;">DeconvNet</a> <a href="/tags/Deep-Learning/" style="font-size: 17.27px;">Deep Learning</a> <a href="/tags/Disjoint-Set/" style="font-size: 11.82px;">Disjoint Set</a> <a href="/tags/Divide-and-Conquer/" style="font-size: 13.64px;">Divide and Conquer</a> <a href="/tags/GAN/" style="font-size: 10.91px;">GAN</a> <a href="/tags/Graph/" style="font-size: 13.64px;">Graph</a> <a href="/tags/Greedy/" style="font-size: 11.82px;">Greedy</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/HihoCoder/" style="font-size: 16.36px;">HihoCoder</a> <a href="/tags/IPv6/" style="font-size: 10px;">IPv6</a> <a href="/tags/LintCode/" style="font-size: 20px;">LintCode</a> <a href="/tags/Machine-Learning/" style="font-size: 10.91px;">Machine Learning</a> <a href="/tags/Matrix/" style="font-size: 10px;">Matrix</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/Normalization/" style="font-size: 10px;">Normalization</a> <a href="/tags/Notes/" style="font-size: 10px;">Notes</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/POJ/" style="font-size: 10.91px;">POJ</a> <a href="/tags/Permutation/" style="font-size: 10px;">Permutation</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Queue/" style="font-size: 10.91px;">Queue</a> <a href="/tags/RL/" style="font-size: 10px;">RL</a> <a href="/tags/Recursion/" style="font-size: 12.73px;">Recursion</a> <a href="/tags/ResNet/" style="font-size: 10px;">ResNet</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/String/" style="font-size: 11.82px;">String</a> <a href="/tags/VPS/" style="font-size: 10px;">VPS</a> <a href="/tags/WhatEver/" style="font-size: 10px;">WhatEver</a>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2020 Watson Yang
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'light-disqus';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<div id="totop" style="position:fixed;bottom:35px;right:20px;cursor: pointer;">
  <a title="返回顶部"><i class="fa fa-angle-double-up fa-3x" aria-hidden="true"></i></a>
</div>
<script src="/js/totop.js"></script>

</body>
</html>
