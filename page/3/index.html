<!DOCTYPE HTML>
<html>

<head>
  <meta name="google-site-verification" content="6-Grm86DHfS67XSHMuvfO8cIcQcOWPpjGvOBMxbA3Fo" />
  <meta charset="utf-8">
  
  <title>Page 3 | WatsonYang&#39;s Blog</title>
  
  <meta name="author" content="Watson Yang">
  
  <meta name="description" content="My secret private space.">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="WatsonYang&#39;s Blog" />

  
  <meta property="og:image" content="" />
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml"
    title="WatsonYang&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  


  <a href="https://github.com/watsonyanghx" target="_blank">
    <img style="position: absolute; top: 0; left: 0; border: 0;"
      src="https://s3.amazonaws.com/github/ribbons/forkme_left_gray_6d6d6d.png" alt="Fork me on GitHub">
  </a>
  <script src="https://use.fontawesome.com/4eb261e456.js"></script>

  <script>
    MathJax = {
      tex: {
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>
<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">WatsonYang&#39;s Blog</a></h1>
  <h2><a href="/">Enrich yourself.</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/about">About</a></li>
    

    <li> <a href="/atom.xml">RSS</a> </li>
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-02-25T15:04:26.000Z"><a href="/2017/02/25/Chapter-9-Convolutional-Networks/">2017-02-25</a></time>
      
      
  
    <h1 class="title"><a href="/2017/02/25/Chapter-9-Convolutional-Networks/">Chapter 9 Convolutional Networks</a></h1>
  

    </header>
    <div class="entry">
      
        <p>这一章可能是因为比较了解的原因，没有找到感觉需要强调的地方。</p>
<p>不知道为什么最近读这本书，突然产生了怀疑：到底应不应该花时间读这本书，用读这本书的时间去多读点论文是不是会更好？或者多多动手实现一下算法是不是会收获更多？</p>
<p>总感觉时间确实很紧张，有很多事情需要去做。却不知道应该把时间花在哪件事情上会更值得。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/02/25/Chapter-9-Convolutional-Networks/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-02-25T15:01:24.000Z"><a href="/2017/02/25/Chapter-8-Optimization-for-Training-Deep-Models/">2017-02-25</a></time>
      
      
  
    <h1 class="title"><a href="/2017/02/25/Chapter-8-Optimization-for-Training-Deep-Models/">Chapter 8 Optimization for Training Deep Models</a></h1>
  

    </header>
    <div class="entry">
      
        <p>非常抱歉，这一张基本上没怎么看，只是大致的浏览了一下。</p>
<p>原因是，这章基本上都是理论的介绍，感觉对做工程的可能没有太大帮助（如果你是研究这个的phD，而且你对这方面也不是很了解，还是很建议你好好读一下的），另外<code>Neural Networks</code>的 optimization 本身就像是个黑盒子。</p>
<p>这一部分感觉目前对我的帮助真的不大，打算是等到以后遇到相关问题后再回来复习吧。</p>
<p>This chapter focuses on <strong>one particular case of optimization</strong>: finding the parameters θ of a neural network that significantly <strong>reduce a cost function J(θ)</strong>, which typically includes a performance measure evaluated on the <strong>entire training set</strong> as well as <strong>additional regularization terms</strong>。</p>
<h1 id="8-1-How-Learning-Differs-from-Pure-Optimization"><a href="#8-1-How-Learning-Differs-from-Pure-Optimization" class="headerlink" title="8.1 How Learning Differs from Pure Optimization"></a>8.1 How Learning Differs from Pure Optimization</h1><p>前面有个小节就是关于<code>optimization</code>的，在那里也说了：<code>ML</code>只是利用 <code>optimization</code> 的方法来进行训练，它的终极目标是<code>test error</code>尽可能的小；而 <code>optimization</code> 是希望完全的拟合数据。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/02/25/Chapter-8-Optimization-for-Training-Deep-Models/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-02-25T14:55:40.000Z"><a href="/2017/02/25/Chapter-7-Regularization-for-Deep-Learning/">2017-02-25</a></time>
      
      
  
    <h1 class="title"><a href="/2017/02/25/Chapter-7-Regularization-for-Deep-Learning/">Chapter 7 Regularization for Deep Learning</a></h1>
  

    </header>
    <div class="entry">
      
        <p>首先，介绍了<code>regularization</code>的定义：</p>
<blockquote>
<p>any modification we make to a learning algorithm that is intended to reduce its generalization error but not its training error.</p>
</blockquote>
<p>也就是说<code>regularization</code>的<font color='red'>目的</font>是：通过<strong>控制模型复杂度</strong>的方式，尽量减轻模型<code>overfitting</code>的程度，提高<code>generalization</code>能力。</p>
<ul>
<li><p><code>regularization</code>的大致可以分为以下几类：</p>
<ul>
<li><p>作用对象/实现方式</p>
<ul>
<li>put extra constraints on a <strong>machine learning model</strong>，such as adding restrictions on the <strong>parameter</strong> values。</li>
<li>add extra terms in the <strong>objective function</strong> that can be thought of as corresponding to a <strong>soft constraint</strong> on the parameter values。</li>
</ul>
</li>
<li><p>原因
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/02/25/Chapter-7-Regularization-for-Deep-Learning/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-02-24T12:26:23.000Z"><a href="/2017/02/24/Chapter-6-Deep-Feedforward-Networks/">2017-02-24</a></time>
      
      
  
    <h1 class="title"><a href="/2017/02/24/Chapter-6-Deep-Feedforward-Networks/">Chapter 6 Deep Feedforward Networks</a></h1>
  

    </header>
    <div class="entry">
      
        <p>首先，介绍了<code>Deep feedforward networks</code>的概念：之所以称为<code>networks</code>，是因为它们是通过把不同的函数组合起来的形式表达的（typically represented by composing together many different functions）；<code>feedforward</code>是因为 no feedback connections in which outputs of the model are fed back into itself（）。</p>
<p>然后，介绍了<code>output layer</code>与<code>hidden layer</code>。training examples 决定了的<code>output layer</code>的行为：输出要接近目标值<code>y</code>。但是它并没有定义<code>hidden layer</code>的行为，不过 learning algorithm 则必须决定如何使用这些<code>hidden layer</code>来完成对函数的逼近。</p>
<p>接着，引入了非线性函数的概念（不是<code>activation function</code>，是指最终学出来的那个函数），指出得到非线性函数的方法有3种：</p>
<ol>
<li><p>使用一个比较 generic 的函数，比如<code>RBF kernel</code>，但最终在 test dataset 上的效果非常不好（generalization to the test set often remains poor）。</p>
</li>
<li><p>使用 domain knowledge 人工指定，但是太费时费力。</p>
</li>
<li><p>算法自己学习，这种方法既可以保证第一种方法的 generic 的性质，又能保证第二种 domain knowledge 的优点（人为的设置一些biased）。</p>
</li>
</ol>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/02/24/Chapter-6-Deep-Feedforward-Networks/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-02-22T16:40:27.000Z"><a href="/2017/02/23/Chapter-5-Machine-Learning-Basics/">2017-02-23</a></time>
      
      
  
    <h1 class="title"><a href="/2017/02/23/Chapter-5-Machine-Learning-Basics/">Chapter 5 Machine Learning Basics</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="《Deep-Learning》-读书笔记"><a href="#《Deep-Learning》-读书笔记" class="headerlink" title="《Deep Learning》 读书笔记"></a>《Deep Learning》 读书笔记</h1><p>写这个笔记的目的有两个：一是以高层的角度把整个章节的内容联系起来，从而加深自己的理解，同时也可以供日后复习使用；二是在日后的组会中可能会降到的时候，有东西可以讲（好偷懒 -_-）。</p>
<p>因为是刚入门的新手，有很多东西还不了解，或者了解的不透彻，肯定会有错误和疏漏的地方，希望大家不吝赐教哈～～</p>
<h1 id="5-1-Learning-Algorithms"><a href="#5-1-Learning-Algorithms" class="headerlink" title="5.1 Learning Algorithms"></a>5.1 Learning Algorithms</h1><p>首先，提出了经典的<code>ML</code>的定义：</p>
<blockquote>
<p>A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P , if its performance at tasks in T , as measured by P , improves with experience E.</p>
</blockquote>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/02/23/Chapter-5-Machine-Learning-Basics/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-02-13T16:51:14.000Z"><a href="/2017/02/14/CS231n-Notes-2/">2017-02-14</a></time>
      
      
  
    <h1 class="title"><a href="/2017/02/14/CS231n-Notes-2/">CS231n Notes 2</a></h1>
  

    </header>
    <div class="entry">
      
        <p>CS231n课程笔记，记录自己看懂和没看懂的地方。这里是<a href="https://watsonyanghx.github.io/2017/01/15/CS231n-Notes-1/">CS231n Notes 1</a>。</p>
<h2 id="Lecture-9"><a href="#Lecture-9" class="headerlink" title="Lecture 9"></a><strong>Lecture 9</strong></h2><h2 id="Lecture-10"><a href="#Lecture-10" class="headerlink" title="Lecture 10"></a><strong>Lecture 10</strong></h2><h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a><strong>RNN</strong></h3><ol>
<li><p>输出层的输出只与当前的隐藏状态有关，而隐藏层可以认为是网络的记忆单元，一般只记忆前面若干步的隐藏状态。</p>
</li>
<li><p><code>RNN</code>的权重是共享的，也就是<code>输入--&gt;隐层，隐层--&gt;隐层，隐层--&gt;输出</code>的权重矩阵（分别是<code>U</code>、<code>W</code> 与 <code>V</code>），在每一层都是对同一个进行更新。</p>
</li>
<li><p><code>RNN</code>并不是每一步都必须有输入与输出，但必须有隐层，用于捕捉序列的信息。</p>
</li>
<li><p><code>RNN</code>训练用<code>BPTT</code>，但<code>BPTT</code>无法解决长时以来问题（即当前输出与前面一段较长的序列相关，可能会带来梯度消失）。</p>
</li>
</ol>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/02/14/CS231n-Notes-2/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-01-19T04:33:11.000Z"><a href="/2017/01/19/Frequently-used-Numpy-functions/">2017-01-19</a></time>
      
      
  
    <h1 class="title"><a href="/2017/01/19/Frequently-used-Numpy-functions/">Frequently-used Numpy Functions</a></h1>
  

    </header>
    <div class="entry">
      
        <ul>
<li>np.argsort</li>
</ul>
<ul>
<li>np.array_split</li>
</ul>
<ul>
<li>np.argmax</li>
</ul>
<ul>
<li>np.argsort</li>
</ul>
<ul>
<li>np.bincount</li>
</ul>
<ul>
<li>np.flatten</li>
</ul>
<ul>
<li>np.flatnonzero</li>
</ul>
<ul>
<li><p>np.hstack</p>
<p>  <a href="http://blog.csdn.net/garfielder007/article/details/51378296" target="_blank" rel="noopener">Python numpy函数hstack() vstack() stack() dstack() vsplit() concatenate()</a></p>
</li>
<li><p>np.linalg.norm</p>
<p>  <a href="http://blog.csdn.net/lanchunhui/article/details/51004387" target="_blank" rel="noopener">np.linalg</a></p>
</li>
</ul>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/01/19/Frequently-used-Numpy-functions/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-01-17T17:35:56.000Z"><a href="/2017/01/18/CS231n-Assignment/">2017-01-18</a></time>
      
      
  
    <h1 class="title"><a href="/2017/01/18/CS231n-Assignment/">CS231n Assignment</a></h1>
  

    </header>
    <div class="entry">
      
        <p><code>CS231n</code>课程作业，记录自己弄懂和没弄懂的地方。第一个作业难度不大，感觉都是在练习<code>numpy</code>的使用（相关函数的总结可以看 <a href="https://watsonyanghx.github.io/2017/01/19/Frequently-used-Numpy-functions/">Frequently-used-Numpy-functions</a>），特别是矩阵运算（广播等）。</p>
<p>因为在代码中相应部分都有注释（基本就相当于在代码里直接进行讲解了），感觉这里没有必要写个博客详细讲解，所以这里只是随便记录一些感觉还算重要的东西，以便日后复习。</p>
<p>具体代码可以见<code>github</code>的 <a href="https://github.com/watsonyanghx/CS231n" target="_blank" rel="noopener">CS231n</a>。</p>
<h2 id="CS231n-Assignment-1"><a href="#CS231n-Assignment-1" class="headerlink" title="CS231n Assignment 1"></a>CS231n Assignment 1</h2><h3 id="Q1-k-Nearest-Neighbor-classifier"><a href="#Q1-k-Nearest-Neighbor-classifier" class="headerlink" title="Q1: k-Nearest Neighbor classifier"></a>Q1: k-Nearest Neighbor classifier</h3><ol>
<li><p>与大多数分类器一样，<code>KNN</code>分为两个步骤：<code>train</code>和<code>predict</code>。但不同的是，严格来说<code>KNN</code>没有<code>train</code>的过程（<code>KNN</code>的<code>train</code>过程就是“记住”所有的数据），在实际代码中通常按照下面的做（在 <a href="https://github.com/watsonyanghx/CS231n/blob/master/assignment1/knn.ipynb" target="_blank" rel="noopener">knn.ipynb</a> 的第<code>6</code>个<code>cell</code>中也有提到）：</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/01/18/CS231n-Assignment/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-01-16T06:54:25.000Z"><a href="/2017/01/16/Unique-Binary-Search-Trees-II/">2017-01-16</a></time>
      
      
  
    <h1 class="title"><a href="/2017/01/16/Unique-Binary-Search-Trees-II/">Unique Binary Search Trees II</a></h1>
  

    </header>
    <div class="entry">
      
        <blockquote>
<p><a href="https://www.lintcode.com/en/problem/unique-binary-search-trees-ii/" target="_blank" rel="noopener">Unique Binary Search Trees II</a></p>
<p><strong>Description:</strong></p>
<p>Given n, generate all structurally unique BST’s (binary search trees) that store values 1…n.</p>
<p><strong>Example:</strong></p>
<p>Given n = 3, your program should return all 5 unique BST’s shown below.</p>
<pre><code>1           3    3       2      1
 \         /    /       / \      \
  3      2     1       1   3      2
 /      /       \                  \
2     1          2                  3</code></pre></blockquote>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/01/16/Unique-Binary-Search-Trees-II/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-01-16T06:39:20.000Z"><a href="/2017/01/16/Hidden-Markov-Model/">2017-01-16</a></time>
      
      
  
    <h1 class="title"><a href="/2017/01/16/Hidden-Markov-Model/">Hidden Markov Model</a></h1>
  

    </header>
    <div class="entry">
      
        <p>这篇只是个人为了加深对<code>Markov Model</code>的理解而做的学习笔记，基本是以易于理解的目的进行组织，所以可能有很多地方不太严禁。如有错误，还请不吝指出。</p>
<h1 id="Markov-Process"><a href="#Markov-Process" class="headerlink" title="Markov Process"></a>Markov Process</h1><ul>
<li><p>一个<code>Markov Process</code>是状态间的转移仅依赖于前<code>n</code>个状态的过程。这个过程被称之为<code>n</code>阶马尔科夫模型，其中<code>n</code>是影响下一个状态选择的（前）<code>n</code>个状态。</p>
<p>最简单的<code>Markov Process</code>是一阶模型，它的状态选择仅与前一个状态有关。</p>
</li>
<li><p><code>Markov Process</code>有两个假设：</p>
<ul>
<li><p>系统在时刻t的状态只与时刻<code>t-1</code>处的状态相关（也称为无后效性）。</p>
<p>用如下公式表示：<code>P(qt=Sj|qt-1=Si,qt-2=Sk,…) =  P(qt=Sj|qt-1=Si)</code>，<code>t</code>为大于<code>1</code>的任意数值，<code>Sk</code>为任意状态</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/01/16/Hidden-Markov-Model/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
    <a href="/page/2/" class="alignleft prev">Prev</a>
  
  
    <a href="/page/4/" class="alignright next">Next</a>
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:watsonyanghx.github.io">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">Categories</h3>
  <ul class="entry">
  
    <li><a href="/categories/Algorithm/">Algorithm</a><small>2</small></li>
  
    <li><a href="/categories/C/">C++</a><small>5</small></li>
  
    <li><a href="/categories/Computer-Vision/">Computer Vision</a><small>3</small></li>
  
    <li><a href="/categories/Deep-Learning/">Deep Learning</a><small>3</small></li>
  
    <li><a href="/categories/Interview/">Interview</a><small>1</small></li>
  
    <li><a href="/categories/Machine-Learning/">Machine Learning</a><small>8</small></li>
  
    <li><a href="/categories/NLP/">NLP</a><small>1</small></li>
  
    <li><a href="/categories/OJ/">OJ</a><small>48</small></li>
  
    <li><a href="/categories/Paper/">Paper</a><small>5</small></li>
  
    <li><a href="/categories/Reinforcement-Learning/">Reinforcement Learning</a><small>1</small></li>
  
    <li><a href="/categories/Technique-Summaries/">Technique Summaries</a><small>2</small></li>
  
    <li><a href="/categories/Tools/">Tools</a><small>1</small></li>
  
    <li><a href="/categories/WhatEver/">WhatEver</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">Tag Cloud</h3>
  <div class="entry">
    <a href="/tags/Algorithm/" style="font-size: 18.18px;">Algorithm</a> <a href="/tags/BFS/" style="font-size: 11.82px;">BFS</a> <a href="/tags/Backtracking/" style="font-size: 12.73px;">Backtracking</a> <a href="/tags/Binary-Tree/" style="font-size: 14.55px;">Binary Tree</a> <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/CNN/" style="font-size: 15.45px;">CNN</a> <a href="/tags/CS231n/" style="font-size: 11.82px;">CS231n</a> <a href="/tags/Combinatorial-number/" style="font-size: 10.91px;">Combinatorial number</a> <a href="/tags/DFS/" style="font-size: 14.55px;">DFS</a> <a href="/tags/DP/" style="font-size: 19.09px;">DP</a> <a href="/tags/Data-structure/" style="font-size: 10.91px;">Data structure</a> <a href="/tags/DeconvNet/" style="font-size: 10px;">DeconvNet</a> <a href="/tags/Deep-Learning/" style="font-size: 17.27px;">Deep Learning</a> <a href="/tags/Disjoint-Set/" style="font-size: 11.82px;">Disjoint Set</a> <a href="/tags/Divide-and-Conquer/" style="font-size: 13.64px;">Divide and Conquer</a> <a href="/tags/GAN/" style="font-size: 10.91px;">GAN</a> <a href="/tags/Graph/" style="font-size: 13.64px;">Graph</a> <a href="/tags/Greedy/" style="font-size: 11.82px;">Greedy</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/HihoCoder/" style="font-size: 16.36px;">HihoCoder</a> <a href="/tags/IPv6/" style="font-size: 10px;">IPv6</a> <a href="/tags/LintCode/" style="font-size: 20px;">LintCode</a> <a href="/tags/Machine-Learning/" style="font-size: 10.91px;">Machine Learning</a> <a href="/tags/Matrix/" style="font-size: 10px;">Matrix</a> <a href="/tags/Metaprogramming/" style="font-size: 10px;">Metaprogramming</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/Normalization/" style="font-size: 10px;">Normalization</a> <a href="/tags/Notes/" style="font-size: 10px;">Notes</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/POJ/" style="font-size: 10.91px;">POJ</a> <a href="/tags/Permutation/" style="font-size: 10px;">Permutation</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Queue/" style="font-size: 10.91px;">Queue</a> <a href="/tags/RL/" style="font-size: 10px;">RL</a> <a href="/tags/Recursion/" style="font-size: 12.73px;">Recursion</a> <a href="/tags/ResNet/" style="font-size: 10px;">ResNet</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/String/" style="font-size: 11.82px;">String</a> <a href="/tags/Template/" style="font-size: 10.91px;">Template</a> <a href="/tags/VPS/" style="font-size: 10px;">VPS</a> <a href="/tags/WhatEver/" style="font-size: 10px;">WhatEver</a>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2020 Watson Yang
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'light-disqus';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<div id="totop" style="position:fixed;bottom:35px;right:20px;cursor: pointer;">
  <a title="返回顶部"><i class="fa fa-angle-double-up fa-3x" aria-hidden="true"></i></a>
</div>
<script src="/js/totop.js"></script>

</body>
</html>
