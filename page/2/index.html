<!DOCTYPE HTML>
<html>

<head>
  <meta name="google-site-verification" content="6-Grm86DHfS67XSHMuvfO8cIcQcOWPpjGvOBMxbA3Fo" />
  <meta charset="utf-8">
  
  <title>Page 2 | WatsonYang&#39;s Blog</title>
  
  <meta name="author" content="Watson Yang">
  
  <meta name="description" content="My secret private space.">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="WatsonYang&#39;s Blog" />

  
  <meta property="og:image" content="" />
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml"
    title="WatsonYang&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  


  <a href="https://github.com/watsonyanghx" target="_blank">
    <img style="position: absolute; top: 0; left: 0; border: 0;"
      src="https://s3.amazonaws.com/github/ribbons/forkme_left_gray_6d6d6d.png" alt="Fork me on GitHub">
  </a>
  <script src="https://use.fontawesome.com/4eb261e456.js"></script>

  <script>
    MathJax = {
      tex: {
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>
<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">WatsonYang&#39;s Blog</a></h1>
  <h2><a href="/">Enrich yourself.</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/about">About</a></li>
    

    <li> <a href="/atom.xml">RSS</a> </li>
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2020-04-25T08:13:23.000Z"><a href="/2020/04/25/Normalization-in-DL/">2020-04-25</a></time>
      
      
  
    <h1 class="title"><a href="/2020/04/25/Normalization-in-DL/">Normalization in DL</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h2><p>注意：<code>归一化</code> 与 <code>标准化</code> 不是同一个概念。</p>
<ul>
<li><p>为什么要进行归一化？</p>
<ul>
<li>去除不同特征之间由于单位不同导致的差别（比如身高用m，体重用kg）。</li>
</ul>
</li>
<li><p>归一化的作用</p>
<ul>
<li><p>加快梯度下降算法的收敛。（归一化之后损失函数的等高线由椭圆变成了圆，梯度直接朝向最小点移动）</p>
<p>如果不进行归一化，由于特征向量中不同特征的取值相差较大，会导致目标函数变“扁”。这样在进行梯度下降的时候，梯度的方向就会偏离最小值的方向，增大训练时间。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2020/04/25/Normalization-in-DL/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2020-04-25T08:04:00.000Z"><a href="/2020/04/25/Initialization-in-DL/">2020-04-25</a></time>
      
      
  
    <h1 class="title"><a href="/2020/04/25/Initialization-in-DL/">Initialization in DL</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="Category"><a href="#Category" class="headerlink" title="Category"></a>Category</h2><h3 id="Lecun"><a href="#Lecun" class="headerlink" title="Lecun"></a>Lecun</h3><ul>
<li><p>Uniform</p>
<p>It draws samples from a uniform distribution within [-limit, limit] where limit is <code>limit = sqrt(3. / fan_in)</code>。</p>
<p><code>fan_in</code>: the number of input units in the weight tensor。</p>
<p>Tensorflow中的函数：</p>
<ul>
<li><p><a href="https://www.tensorflow.org/api_docs/python/tf/keras/initializers/lecun_uniform" target="_blank" rel="noopener">tf.initializers.lecun_uniform</a></p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2020/04/25/Initialization-in-DL/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2020-04-25T05:44:32.000Z"><a href="/2020/04/25/Optimization-Method-in-DL/">2020-04-25</a></time>
      
      
  
    <h1 class="title"><a href="/2020/04/25/Optimization-Method-in-DL/">Optimization Method in DL</a></h1>
  

    </header>
    <div class="entry">
      
        <h1 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h1><p>$$<br>\theta_{t+1,i} = \theta_{t,i} - \eta·g_{t,i}<br>$$</p>
<ul>
<li><p>缺点：</p>
<ul>
<li><p>SGD 最大的缺点是下降速度慢。</p>
</li>
<li><p>可能会在沟壑（“盆地”）的两边持续震荡，停留在一个局部最优点，可能无法从中出来，也就无法继续优化。（所以需要细心的初始化参数）。</p>
</li>
<li><p>遇到“鞍点/平原”，可能停止更新（梯度都是 $ 0 $）。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2020/04/25/Optimization-Method-in-DL/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-05-19T05:28:36.000Z"><a href="/2017/05/19/Striving-for-Simplicity-The-All-Convolutional-Net/">2017-05-19</a></time>
      
      
  
    <h1 class="title"><a href="/2017/05/19/Striving-for-Simplicity-The-All-Convolutional-Net/">Striving for Simplicity: The All Convolutional Net</a></h1>
  

    </header>
    <div class="entry">
      
        <ul>
<li><p>contribution</p>
<ul>
<li><p><code>stride convoulution</code>替代<code>pooling</code>，实现没有<code>pooling</code>的 network</p>
</li>
<li><p><code>guided backpropagation</code>，可视化的新方法，可以在没有</p>
</li>
</ul>
</li>
<li><p>有2种方法去掉<code>pooling</code>，并且不影响网络的性能:</p>
<ul>
<li><p>增大它前面一层的<code>convolution</code>层的stride，目的是起到类似<code>pooling</code>的降维作用。</p>
<ul>
<li>这种做法有问题：虽然起到了降维的作用，但是相对于<code>pooling</code>，相当于只考虑了top-left的features，实验结果证实效果确实不好。</li>
</ul>
</li>
<li><p>把这一层的<code>pooling</code>换成简单的<code>convolution</code>，但要保证：（1）相同大小的 filter size 和 stride；（2）和<code>pooling</code>相同大小的输出。</p>
<ul>
<li><p>这种没有前一种的问题，但是增加了 parameters 的数量。</p>
</li>
<li><p>作者说这可以看成是主动的学习<code>pooling</code>，而不是固定的采用<code>max/avg</code>等方式。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/05/19/Striving-for-Simplicity-The-All-Convolutional-Net/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-04-21T16:24:46.000Z"><a href="/2017/04/22/Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks/">2017-04-22</a></time>
      
      
  
    <h1 class="title"><a href="/2017/04/22/Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks/">Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks</a></h1>
  

    </header>
    <div class="entry">
      
        <p>这篇文章最主要的<strong>目的</strong>是把<code>GAN</code>作为一种<code>representation learning</code>的方法（对<code>Generator</code>和<code>Discriminator</code>都是这个目的，而不是生成图片），然后用学到的 features 用于<code>supervised learning</code>（<code>classification</code>等）。做了相关的实验验证（用学到的 features 在其它数据集上进行分类，对学到的<code>features</code>进行可视化）<code>representation learning</code>的效果很好。</p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><ul>
<li><p>无标数据比有标数据多得多，如果能利用这些数据提取 features，然后用于<code>supervised</code>任务，会很有帮助</p>
</li>
<li><p>用于<code>supervised learning</code>的<code>CNN</code>在<code>CV</code>方面取得了取得了很好的成绩，如果用于<code>unsupervised learning</code>是不是也可以取得比较不错的成绩。</p>
</li>
<li><p>最近的<code>GAN</code>很火，那是不是可以把<code>GAN</code>的结构用到<code>CNN</code>中（所以从这个角度看是：用<code>GAN</code>改进<code>CNN</code>，而不是用<code>CNN</code>改进<code>GAN</code>），把<code>CNN</code>改成一种可以用于<code>unsupervised learning</code>任务的结构。</p>
</li>
<li><p>convincing evidence 表明：提出的 model 可以 learns a hierarchy of representations from object parts to scenes </p>
</li>
</ul>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/04/22/Unsupervised-Representation-Learning-with-Deep-Convolutional-Generative-Adversarial-Networks/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-04-11T17:18:52.000Z"><a href="/2017/04/12/Longest-Common-Substring/">2017-04-12</a></time>
      
      
  
    <h1 class="title"><a href="/2017/04/12/Longest-Common-Substring/">Longest Common Substring</a></h1>
  

    </header>
    <div class="entry">
      
        <blockquote>
<p><a href="https://www.lintcode.com/en/problem/longest-common-substring/" target="_blank" rel="noopener">Longest Common Substring</a></p>
<p><strong>Description:</strong></p>
<p>Given two strings, find the longest common substring. Return the length of it.</p>
<p><strong>Notice:</strong></p>
<p>The characters in substring should occur continuously in original string. This is different with subsequence.</p>
<p><strong>Example:</strong></p>
<p>Given A = “ABCD”, B = “CBCE”, return 2.</p>
</blockquote>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/04/12/Longest-Common-Substring/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-29T11:41:49.000Z"><a href="/2017/03/29/Learning-Deconvolution-Network-for-Semantic-Segmentation/">2017-03-29</a></time>
      
      
  
    <h1 class="title"><a href="/2017/03/29/Learning-Deconvolution-Network-for-Semantic-Segmentation/">Learning Deconvolution Network for Semantic Segmentation</a></h1>
  

    </header>
    <div class="entry">
      
        <p>这个就是大家所说的<strong>反卷积网络</strong>。</p>
<h2 id="Category-of-Deconvolution"><a href="#Category-of-Deconvolution" class="headerlink" title="Category of Deconvolution"></a>Category of Deconvolution</h2><p><code>Deconvolution</code>在<code>Deep Learning</code>领域大致可以分为下面 2 个种类。</p>
<ul>
<li><p>Transposed Convolution</p>
<p><code>convolution</code>的反转过程，这篇 paper 讲的就是这个。</p>
</li>
<li><p>Convolutional Sparse Coding</p>
<p>它是一种<code>representation learning</code>的一种，<strong>目的</strong>是根据从图像中学到的<code>features</code>完全的<strong>还原</strong>图像。</p>
</li>
</ul>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/03/29/Learning-Deconvolution-Network-for-Semantic-Segmentation/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-29T09:07:45.000Z"><a href="/2017/03/29/Deep-Residual-Learning-for-Image-Recognition/">2017-03-29</a></time>
      
      
  
    <h1 class="title"><a href="/2017/03/29/Deep-Residual-Learning-for-Image-Recognition/">Deep Residual Learning for Image Recognition</a></h1>
  

    </header>
    <div class="entry">
      
        <p>这个就是大家所说的<code>ResNet</code>——<strong>残差网络</strong>。</p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>很多实验都证明网络的<strong>深度</strong>对网络的效果有着很重要的影响，理论上网络层数<strong>越多</strong>，得到的效果会<strong>越好</strong>，但是作者做了实验却发现网络的深度与网络在<code>test dataset</code>上的<code>error rate</code>是一个<code>U</code>形的曲线。也就是说当网络达到<strong>一定深度</strong>后，再增加深度，效果会变差，作者把这种现象称为<code>Degradation Problem</code>。</p>
  <center>
  <img src="https://www.tuchuang001.com/images/2017/03/29/QQ20170329202816.png" alt="Degradation Problem" border="0" />
  </center>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/03/29/Deep-Residual-Learning-for-Image-Recognition/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-10T05:41:29.000Z"><a href="/2017/03/10/Maxout-Networks-Network-in-Network/">2017-03-10</a></time>
      
      
  
    <h1 class="title"><a href="/2017/03/10/Maxout-Networks-Network-in-Network/">Maxout Networks &amp; Network in Network</a></h1>
  

    </header>
    <div class="entry">
      
        <h2 id="Maxout-Networks"><a href="#Maxout-Networks" class="headerlink" title="Maxout Networks"></a>Maxout Networks</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p><code>dropout</code>是一种 regularization 的方法，主要作用是用来减轻过拟合现象。实现方式是：以一定的概率，随机的把<code>hidden units</code>的输出值设成<code>0</code>，也就是随机的让某些<code>hidden units</code>失活，此时就相当于是一种集成模型的训练。</p>
<p>实验证实当网络比较深的时候，使用<code>dropout</code>能够很好的提升网络的 generalization 能力。</p>
<p>作者就想：如果不只是单单的把它作为一种提升模型性能的工具，而是直接应用到网络结构的内部，是不是能够更好的提高网络的性能呢？</p>
<p>注意：<code>dropout</code>只是一种 regularizer，而<code>maxout</code>是一种网络结构。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/03/10/Maxout-Networks-Network-in-Network/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>




  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-02-25T15:05:53.000Z"><a href="/2017/02/25/Chapter-10-Sequence-Modeling-Recurrent-and-Recursive-Nets/">2017-02-25</a></time>
      
      
  
    <h1 class="title"><a href="/2017/02/25/Chapter-10-Sequence-Modeling-Recurrent-and-Recursive-Nets/">Chapter 10 Sequence Modeling: Recurrent and Recursive Nets</a></h1>
  

    </header>
    <div class="entry">
      
        <p>最近比较浮躁，书读不进去，总结也写不下去。虽然感觉有很多事情要做，却有种分不清主次的感觉。啊啊啊啊啊啊啊啊，什么时候才是个头啊！！！！！！</p>
<p>这一 Chapter 的很多内容都没有仔细的去看，所以这个总结里的内容也很少，会在后面慢慢的补充上来 -_- </p>
<p>首先，介绍了<code>RNN</code>的定义：</p>
<blockquote>
<p>Recurrent neural networks or RNNs (Rumelhart et al., 1986a) are a family of neural networks for processing sequential data. specialized for processing a sequence of values x<sup>(1)</sup>, . . . , x<sup>(τ)</sup>.</p>
</blockquote>
<p>也就是在每一步都有新的输入，所以从某种角度它也算是一种<code>Feedforward Networks</code>。</p>
<p>另外，这里介绍了<code>RNN</code>的<code>parameter sharing</code>机制：Each member of the output is produced using the <strong>same update rule</strong> applied to the <strong>previous outputs</strong>. This recurrent formulation results in the sharing of parameters through a very deep <strong>computational graph</strong>.</p>
<p>Sharing Parameters is key to RNNs。书中举得 “I went to Nepal in 1999 ” and “In 1999, I went to Nepal ”的例子就是为了说明这个重要性。</p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2017/02/25/Chapter-10-Sequence-Modeling-Recurrent-and-Recursive-Nets/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>





<nav id="pagination">
  
    <a href="/" class="alignleft prev">Prev</a>
  
  
    <a href="/page/3/" class="alignright next">Next</a>
  
  <div class="clearfix"></div>
</nav></div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:watsonyanghx.github.io">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">Categories</h3>
  <ul class="entry">
  
    <li><a href="/categories/Algorithm/">Algorithm</a><small>2</small></li>
  
    <li><a href="/categories/C/">C++</a><small>5</small></li>
  
    <li><a href="/categories/Computer-Vision/">Computer Vision</a><small>3</small></li>
  
    <li><a href="/categories/Deep-Learning/">Deep Learning</a><small>3</small></li>
  
    <li><a href="/categories/Interview/">Interview</a><small>1</small></li>
  
    <li><a href="/categories/Machine-Learning/">Machine Learning</a><small>8</small></li>
  
    <li><a href="/categories/NLP/">NLP</a><small>1</small></li>
  
    <li><a href="/categories/OJ/">OJ</a><small>48</small></li>
  
    <li><a href="/categories/Paper/">Paper</a><small>5</small></li>
  
    <li><a href="/categories/Reinforcement-Learning/">Reinforcement Learning</a><small>1</small></li>
  
    <li><a href="/categories/Technique-Summaries/">Technique Summaries</a><small>2</small></li>
  
    <li><a href="/categories/Tools/">Tools</a><small>1</small></li>
  
    <li><a href="/categories/WhatEver/">WhatEver</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">Tag Cloud</h3>
  <div class="entry">
    <a href="/tags/Algorithm/" style="font-size: 18.18px;">Algorithm</a> <a href="/tags/BFS/" style="font-size: 11.82px;">BFS</a> <a href="/tags/Backtracking/" style="font-size: 12.73px;">Backtracking</a> <a href="/tags/Binary-Tree/" style="font-size: 14.55px;">Binary Tree</a> <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/CNN/" style="font-size: 15.45px;">CNN</a> <a href="/tags/CS231n/" style="font-size: 11.82px;">CS231n</a> <a href="/tags/Combinatorial-number/" style="font-size: 10.91px;">Combinatorial number</a> <a href="/tags/DFS/" style="font-size: 14.55px;">DFS</a> <a href="/tags/DP/" style="font-size: 19.09px;">DP</a> <a href="/tags/Data-structure/" style="font-size: 10.91px;">Data structure</a> <a href="/tags/DeconvNet/" style="font-size: 10px;">DeconvNet</a> <a href="/tags/Deep-Learning/" style="font-size: 17.27px;">Deep Learning</a> <a href="/tags/Disjoint-Set/" style="font-size: 11.82px;">Disjoint Set</a> <a href="/tags/Divide-and-Conquer/" style="font-size: 13.64px;">Divide and Conquer</a> <a href="/tags/GAN/" style="font-size: 10.91px;">GAN</a> <a href="/tags/Graph/" style="font-size: 13.64px;">Graph</a> <a href="/tags/Greedy/" style="font-size: 11.82px;">Greedy</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/HihoCoder/" style="font-size: 16.36px;">HihoCoder</a> <a href="/tags/IPv6/" style="font-size: 10px;">IPv6</a> <a href="/tags/LintCode/" style="font-size: 20px;">LintCode</a> <a href="/tags/Machine-Learning/" style="font-size: 10.91px;">Machine Learning</a> <a href="/tags/Matrix/" style="font-size: 10px;">Matrix</a> <a href="/tags/Metaprogramming/" style="font-size: 10px;">Metaprogramming</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/Normalization/" style="font-size: 10px;">Normalization</a> <a href="/tags/Notes/" style="font-size: 10px;">Notes</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/POJ/" style="font-size: 10.91px;">POJ</a> <a href="/tags/Permutation/" style="font-size: 10px;">Permutation</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Queue/" style="font-size: 10.91px;">Queue</a> <a href="/tags/RL/" style="font-size: 10px;">RL</a> <a href="/tags/Recursion/" style="font-size: 12.73px;">Recursion</a> <a href="/tags/ResNet/" style="font-size: 10px;">ResNet</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/String/" style="font-size: 11.82px;">String</a> <a href="/tags/Template/" style="font-size: 10.91px;">Template</a> <a href="/tags/VPS/" style="font-size: 10px;">VPS</a> <a href="/tags/WhatEver/" style="font-size: 10px;">WhatEver</a>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2020 Watson Yang
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'light-disqus';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<div id="totop" style="position:fixed;bottom:35px;right:20px;cursor: pointer;">
  <a title="返回顶部"><i class="fa fa-angle-double-up fa-3x" aria-hidden="true"></i></a>
</div>
<script src="/js/totop.js"></script>

</body>
</html>
