<!DOCTYPE HTML>
<html>

<head>
  <meta name="google-site-verification" content="6-Grm86DHfS67XSHMuvfO8cIcQcOWPpjGvOBMxbA3Fo" />
  <meta charset="utf-8">
  
  <title>Deep Residual Learning for Image Recognition | WatsonYang&#39;s Blog</title>
  
  <meta name="author" content="Watson Yang">
  
  <meta name="description" content="My secret private space.">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:title" content="Deep Residual Learning for Image Recognition" />
  <meta property="og:site_name" content="WatsonYang&#39;s Blog" />

  
  <meta property="og:image" content="" />
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml"
    title="WatsonYang&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  


  <a href="https://github.com/watsonyanghx" target="_blank">
    <img style="position: absolute; top: 0; left: 0; border: 0;"
      src="https://s3.amazonaws.com/github/ribbons/forkme_left_gray_6d6d6d.png" alt="Fork me on GitHub">
  </a>
  <script src="https://use.fontawesome.com/4eb261e456.js"></script>

  <script>
    MathJax = {
      tex: {
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>
<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">WatsonYang&#39;s Blog</a></h1>
  <h2><a href="/">Enrich yourself.</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/about">About</a></li>
    

    <li> <a href="/atom.xml">RSS</a> </li>
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-03-29T09:07:45.000Z"><a href="/2017/03/29/Deep-Residual-Learning-for-Image-Recognition/">2017-03-29</a></time>
      
      
  
    <h1 class="title">Deep Residual Learning for Image Recognition</h1>
  

    </header>
    <div class="entry">
      
        <p>这个就是大家所说的<code>ResNet</code>——<strong>残差网络</strong>。</p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>很多实验都证明网络的<strong>深度</strong>对网络的效果有着很重要的影响，理论上网络层数<strong>越多</strong>，得到的效果会<strong>越好</strong>，但是作者做了实验却发现网络的深度与网络在<code>test dataset</code>上的<code>error rate</code>是一个<code>U</code>形的曲线。也就是说当网络达到<strong>一定深度</strong>后，再增加深度，效果会变差，作者把这种现象称为<code>Degradation Problem</code>。</p>
  <center>
  <img src="https://www.tuchuang001.com/images/2017/03/29/QQ20170329202816.png" alt="Degradation Problem" border="0" />
  </center>

<a id="more"></a>

<p>所以从<strong>理论角度</strong>分析：因为使用了<code>normalization</code>，并<strong>不是</strong>梯度消失的问题，而是<strong>网络本身很难学习</strong>。</p>
<p>得出<strong>结论</strong>：很难学习的<strong>原因</strong>是<code>information flow</code>在<code>deep network</code>中受阻，最终导致网络的效果变差。</p>
<p>那如何才能让顺利的传到更深的层中去呢？作者就想到<strong>直接</strong>把信息传递到下层网络中，也就是采用<code>skip connection</code>。</p>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><h3 id="Residual-Learning"><a href="#Residual-Learning" class="headerlink" title="Residual Learning"></a>Residual Learning</h3><ul>
<li><p>Residual Function</p>
<p><strong>动机</strong>是：直接拟合原来的<strong>目标函数</strong>不好弄，可以拟合它的<strong>残差函数</strong>，实际效果很好，虽然不是最好的。</p>
</li>
<li><p>Building Block</p>
<p>以<code>building block</code>为<strong>基本单位</strong>构建残差网络。</p>
<center>
<img src="https://www.tuchuang001.com/images/2017/03/29/QQ20170329183119.png" alt="Building Block" border="0" />
</center>

<p> 设为<code>2</code>层只是根据 intuition，如果只有一层，效果相对<code>Conventional CNN</code>没有提升。</p>
</li>
</ul>
<h3 id="Identity-Mapping-by-Shortcuts"><a href="#Identity-Mapping-by-Shortcuts" class="headerlink" title="Identity Mapping by Shortcuts"></a>Identity Mapping by Shortcuts</h3><ul>
<li><p>主要<strong>目的</strong>是 dealing with <strong>dimension</strong> problem（当把<code>x</code>加到<code>f(x)</code>的时候，可能出现维度不一致的现象），这时有<code>2</code>种解决方式：</p>
<ol>
<li><p>Padding Zero</p>
</li>
<li><p>Projection Shortcuts (done by 1×1 convolutions)</p>
<ul>
<li><p>Projection shortcuts are used for increasing dimensions, and other shortcuts are identity（<strong>只有</strong>在碰到维度不一致的时候，<strong>才</strong>进行<code>projection shortcuts</code>，否则就进行<code>Identity Mapping</code>）。</p>
</li>
<li><p>All shortcuts are projections（<strong>只要</strong>碰到维度问题就进行<code>projection shortcuts</code>）。</p>
</li>
</ul>
</li>
</ol>
<p>实验证实以上两种做法相对于<code>Conventional CNN</code>都提高了效果，其中<strong>最后一种</strong>的效果最好，但是与前面的两种效果的差别不大。所以，作者认为<code>projections</code><strong>不是</strong>提升网络效果的主要原因，所以为了节省计算资源和时间，作者在剩下的试验中采用<code>padding 0</code>的方式。</p>
</li>
</ul>
<ul>
<li>使用<code>stride=2</code>的<code>conv</code>代替了<code>pooling</code>（之前曾经看过一篇文章是讲<code>conv</code>降维至少不会比<code>pooling</code>效果差）。</li>
</ul>
<h3 id="Bottleneck"><a href="#Bottleneck" class="headerlink" title="Bottleneck"></a>Bottleneck</h3><ul>
<li><p>这个概念在<code>Inception</code>的论文中就提出了，如下图右所示。</p>
<center>
<img src="https://www.tuchuang001.com/images/2017/03/29/QQ20170329223203.png" alt="Plan Skip VS Bottleneck" border="0" />
</center>

<p>之所以叫<code>Bottleneck</code>，是因为使用了<code>1x1</code>的卷积操作，<strong>作用</strong>是减少计算量。实验表明，这样<strong>不会</strong>对网络的性能造成坏的影响。</p>
<p>关于<code>Bottleneck</code>，可以参阅参考文献 1 ，其中有一部分讲的就是这个。</p>
</li>
</ul>
<h2 id="Architecture-used-in-experiments"><a href="#Architecture-used-in-experiments" class="headerlink" title="Architecture used in experiments"></a>Architecture used in experiments</h2><ul>
<li><p>No dropout，因为使用了<code>batchnormalization</code></p>
</li>
<li><p>No hidden fc，转化为<code>Global Average Pooling</code></p>
<center>
<img src="https://www.tuchuang001.com/images/2017/03/29/1.png" alt="Example network architectures for ImageNet" border="0" />
</center>

<p><strong>Left</strong>: the VGG-19 model (19.6 billion FLOPs) as a reference. <strong>Middle</strong>: a plain network with 34 parameter layers (3.6 billion FLOPs). <strong>Right</strong>: a residual network with 34 parameter layers (3.6 billion FLOPs). The dotted shortcuts increase dimensions.</p>
</li>
</ul>
<h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><ol>
<li><p>不同深度的<code>Conventional CNN</code>之间的对比：<code>34</code>层的网络效果没有<code>18</code>层的好，但是<strong>没有差别太大</strong>，说明网络正常工作，进一步的说明<strong>不是</strong>梯度消失的问题。</p>
<center>
<img src="https://www.tuchuang001.com/images/2017/03/29/QQ20170329180449.png" alt="34 layers VS 18 layers" border="0" />
</center>
</li>
<li><p>相同深度的<code>Conventional CNN</code>与<code>ResNet</code>的对比。</p>
<ul>
<li><p>网络<strong>较浅</strong>的时候，<code>ResNet</code>的效果<strong>提升不明显</strong>，但是比<code>Conventional CNN</code><strong>收敛更快</strong>。</p>
</li>
<li><p>网络<strong>较深</strong>的时候，<code>ResNet</code>的效果<strong>提升明显</strong>。</p>
</li>
</ul>
</li>
<li><p>不同深度的<code>ResNet</code>之间的对比：<strong>越深越好</strong>。</p>
</li>
<li><p>作者特别的设计了一个<code>1202</code>层的网络，但是<code>training error</code>和<code>110</code>层的网络差不多，但是<code>test error</code>却很差，作者解释是网络太深，数据集太小，产生了<code>overfitting</code>。</p>
</li>
<li><p>实验的具体细节可以看 paper，细节写的挺详细的。</p>
</li>
</ol>
<p>这个网络当时赢得了<code>Object Detection</code>、<code>Image Localization</code>的第一，paper 中以附录的形式对其进行了提及，不过由于时间和精力原因没有去看，这一点不好意思，大家如果有兴趣可以看一下。</p>
<h2 id="Related-work"><a href="#Related-work" class="headerlink" title="Related work"></a>Related work</h2><h3 id="Highway-Networks"><a href="#Highway-Networks" class="headerlink" title="Highway Networks"></a>Highway Networks</h3><p><code>ResNet</code>是<code>Highway Networks</code>的一种特例。没有去看这个 paper，有兴趣的可以去参考。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba" target="_blank" rel="noopener">Neural Network Architectures</a></li>
<li><a href="https://iamaaditya.github.io/2016/03/one-by-one-convolution/" target="_blank" rel="noopener">One by One [ 1 x 1 ] Convolution</a></li>
<li><a href="https://www.zhihu.com/question/56024942" target="_blank" rel="noopener">卷积神经网络中用1*1 卷积有什么作用或者好处呢？ - 知乎</a></li>
</ol>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/Paper/">Paper</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/CNN/">CNN</a>, <a href="/tags/ResNet/">ResNet</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">Comments</h1>

  
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript>
  </div>
  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:watsonyanghx.github.io">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">Categories</h3>
  <ul class="entry">
  
    <li><a href="/categories/Algorithm/">Algorithm</a><small>2</small></li>
  
    <li><a href="/categories/C/">C++</a><small>1</small></li>
  
    <li><a href="/categories/Computer-Vision/">Computer Vision</a><small>3</small></li>
  
    <li><a href="/categories/Deep-Learning/">Deep Learning</a><small>3</small></li>
  
    <li><a href="/categories/Interview/">Interview</a><small>1</small></li>
  
    <li><a href="/categories/Machine-Learning/">Machine Learning</a><small>8</small></li>
  
    <li><a href="/categories/NLP/">NLP</a><small>1</small></li>
  
    <li><a href="/categories/OJ/">OJ</a><small>48</small></li>
  
    <li><a href="/categories/Paper/">Paper</a><small>5</small></li>
  
    <li><a href="/categories/Reinforcement-Learning/">Reinforcement Learning</a><small>1</small></li>
  
    <li><a href="/categories/Technique-Summaries/">Technique Summaries</a><small>2</small></li>
  
    <li><a href="/categories/Tools/">Tools</a><small>1</small></li>
  
    <li><a href="/categories/WhatEver/">WhatEver</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">Tag Cloud</h3>
  <div class="entry">
    <a href="/tags/Algorithm/" style="font-size: 18.18px;">Algorithm</a> <a href="/tags/BFS/" style="font-size: 11.82px;">BFS</a> <a href="/tags/Backtracking/" style="font-size: 12.73px;">Backtracking</a> <a href="/tags/Binary-Tree/" style="font-size: 14.55px;">Binary Tree</a> <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/CNN/" style="font-size: 15.45px;">CNN</a> <a href="/tags/CS231n/" style="font-size: 11.82px;">CS231n</a> <a href="/tags/Combinatorial-number/" style="font-size: 10.91px;">Combinatorial number</a> <a href="/tags/DFS/" style="font-size: 14.55px;">DFS</a> <a href="/tags/DP/" style="font-size: 19.09px;">DP</a> <a href="/tags/Data-structure/" style="font-size: 10.91px;">Data structure</a> <a href="/tags/DeconvNet/" style="font-size: 10px;">DeconvNet</a> <a href="/tags/Deep-Learning/" style="font-size: 17.27px;">Deep Learning</a> <a href="/tags/Disjoint-Set/" style="font-size: 11.82px;">Disjoint Set</a> <a href="/tags/Divide-and-Conquer/" style="font-size: 13.64px;">Divide and Conquer</a> <a href="/tags/GAN/" style="font-size: 10.91px;">GAN</a> <a href="/tags/Graph/" style="font-size: 13.64px;">Graph</a> <a href="/tags/Greedy/" style="font-size: 11.82px;">Greedy</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/HihoCoder/" style="font-size: 16.36px;">HihoCoder</a> <a href="/tags/IPv6/" style="font-size: 10px;">IPv6</a> <a href="/tags/LintCode/" style="font-size: 20px;">LintCode</a> <a href="/tags/Machine-Learning/" style="font-size: 10.91px;">Machine Learning</a> <a href="/tags/Matrix/" style="font-size: 10px;">Matrix</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/Normalization/" style="font-size: 10px;">Normalization</a> <a href="/tags/Notes/" style="font-size: 10px;">Notes</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/POJ/" style="font-size: 10.91px;">POJ</a> <a href="/tags/Permutation/" style="font-size: 10px;">Permutation</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Queue/" style="font-size: 10.91px;">Queue</a> <a href="/tags/RL/" style="font-size: 10px;">RL</a> <a href="/tags/Recursion/" style="font-size: 12.73px;">Recursion</a> <a href="/tags/ResNet/" style="font-size: 10px;">ResNet</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/String/" style="font-size: 11.82px;">String</a> <a href="/tags/VPS/" style="font-size: 10px;">VPS</a> <a href="/tags/WhatEver/" style="font-size: 10px;">WhatEver</a>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2020 Watson Yang
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'light-disqus';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<div id="totop" style="position:fixed;bottom:35px;right:20px;cursor: pointer;">
  <a title="返回顶部"><i class="fa fa-angle-double-up fa-3x" aria-hidden="true"></i></a>
</div>
<script src="/js/totop.js"></script>

</body>
</html>
