<!DOCTYPE HTML>
<html>

<head>
  <meta name="google-site-verification" content="6-Grm86DHfS67XSHMuvfO8cIcQcOWPpjGvOBMxbA3Fo" />
  <meta charset="utf-8">
  
  <title>CS231n Notes 1 | WatsonYang&#39;s Blog</title>
  
  <meta name="author" content="Watson Yang">
  
  <meta name="description" content="My secret private space.">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:title" content="CS231n Notes 1" />
  <meta property="og:site_name" content="WatsonYang&#39;s Blog" />

  
  <meta property="og:image" content="" />
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml"
    title="WatsonYang&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  


  <a href="https://github.com/watsonyanghx" target="_blank">
    <img style="position: absolute; top: 0; left: 0; border: 0;"
      src="https://s3.amazonaws.com/github/ribbons/forkme_left_gray_6d6d6d.png" alt="Fork me on GitHub">
  </a>
  <script src="https://use.fontawesome.com/4eb261e456.js"></script>

  <script>
    MathJax = {
      tex: {
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>
<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">WatsonYang&#39;s Blog</a></h1>
  <h2><a href="/">Enrich yourself.</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/about">About</a></li>
    

    <li> <a href="/atom.xml">RSS</a> </li>
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-01-15T12:08:44.000Z"><a href="/2017/01/15/CS231n-Notes-1/">2017-01-15</a></time>
      
      
  
    <h1 class="title">CS231n Notes 1</h1>
  

    </header>
    <div class="entry">
      
        <p><code>CS231n</code>课程笔记，记录自己看懂和没看懂的地方。</p>
<h2 id="Lecture-4"><a href="#Lecture-4" class="headerlink" title="Lecture 4"></a><strong>Lecture 4</strong></h2><ol>
<li><p><code>gradient</code>的计算。</p>
<ul>
<li><p>在<code>forward</code>阶段就计算当前<code>unit</code>的<code>local gradient</code>。</p>
</li>
<li><p>在<code>backward</code>阶段：<code>local gradient * gradient from above</code>。</p>
</li>
</ul>
</li>
<li><p>add gate, max gate，mul gate</p>
 <a id="more"></a>
</li>
<li><p>backpropagation is an expression for the partial derivative of the cost function  with respect to any weight  (or bias) in the network</p>
</li>
</ol>
<h2 id="Lecture-5"><a href="#Lecture-5" class="headerlink" title="Lecture 5"></a><strong>Lecture 5</strong></h2><ol>
<li><p>权重初始化为什么不能全零初始化？虽然说会打破不对称性，但到底是如何打破的？产生的效果又是什么样的？</p>
<p> 如果全部初始化为<code>0</code>，那么每个<code>unit</code>的输出就会相同，梯度就会相同，参数更新就会相同，那还弄多个<code>units</code>有什么意义（intuitive 上就不对 -_- ）。</p>
<p> 虽然有些措施（<code>ReLu</code>，<code>Dropout</code>）可以在中间打乱这种现象，但是还是不推荐全部初始为<code>0</code>。</p>
</li>
<li><p>批量归一化（<code>Batch Normalization</code>）与<code>Dropout</code>有什么关系？各自在什么情况下用？</p>
<p> <code>Dropout</code>是正则化，用来降低<strong>过拟合</strong>的程度。而<code>Batch Normalization</code>主要用来解决<strong>权重初始化</strong>的问题。</p>
<p> 在实现层面，应用<code>Batch Normalization</code>通常意味着在<code>全连接层</code>（或者是<code>卷积层</code>）与<code>Activation Function</code>之间添加一个<code>BatchNorm</code>层。</p>
<p> <font color='red'>为什么</font>放在<code>FC/CNN</code>之后，<code>Activation Function</code>之前？</p>
<p> 因为前面一层的作用是提取特征，<code>Activation Function</code>的作用是对特征做非线性的变换（更深一层/抽象的提取重要的特征）。放在<code>Activation Function</code>之后显然可以提取到更好（表征能力更强）、更多、更重要的特征。放在后面的话，特征都已经提取了，再做<code>Batch Normalization</code>有什么用？！</p>
<p> 关于<code>Batch Normalization</code>可以参考下面的几个博客。</p>
<ul>
<li><p><a href="http://blog.csdn.net/u012816943/article/details/51691868" target="_blank" rel="noopener">论文笔记-Batch Normalization</a></p>
</li>
<li><p><a href="http://blog.csdn.net/hjimce/article/details/50866313" target="_blank" rel="noopener">深度学习（二十九）Batch Normalization 学习笔记</a></p>
</li>
<li><p><a href="https://www.zhihu.com/question/37129350/answer/70964527#" target="_blank" rel="noopener">为什么 feature scaling 会使 gradient descent 的收敛更好?</a></p>
</li>
</ul>
</li>
<li><p>为什么要进行梯度检查？</p>
<p> 可以验证<code>BP</code>算法的实现是否又逻辑错误（<code>BP</code>算法解决的就是如何计算梯度的问题）。</p>
</li>
<li></li>
</ol>
<h2 id="Lecture-6"><a href="#Lecture-6" class="headerlink" title="Lecture 6"></a><strong>Lecture 6</strong></h2><ol>
<li><p>视频37:50处为什么对 x_test 操作？</p>
</li>
<li><p><code>Dropout</code>操作在反向传播时也进行吗？为什么？</p>
<p>进行。</p>
<p><strong>注意</strong>：在test和infer阶段都不进行<code>Dropout</code>。</p>
</li>
<li><p>51 分钟处没看懂</p>
</li>
</ol>
<h2 id="Lecture-7"><a href="#Lecture-7" class="headerlink" title="Lecture 7"></a><strong>Lecture 7</strong></h2><ol>
<li><p>10分钟处，可视化的是什么？</p>
</li>
<li><p>卷积核对某个特征感性兴趣（被某个特征激活）是什么意思？</p>
</li>
<li><p>图片一般首先预处理成<code>正方形</code>的尺寸。</p>
</li>
<li><p>为什么要用<code>padding</code>？为什么用<code>0</code>填充？什么时候用好？</p>
<p>为什么用：</p>
<ul>
<li>如果不用<code>padding</code>的话，随着网络深度的增加图片的尺寸会逐渐减少，可能会出现卷积核尺寸大于图片尺寸的情况，这时就无法接着处理了。</li>
<li>有种说法是：<code>paading</code>可以降低图片信息的损失</li>
<li>Andrej Karpathy 指出：实际应用中，<code>padding</code>的效果会比不<code>padding</code>的效果更好。</li>
</ul>
<p>为什么用<code>0</code>填充：</p>
<ul>
<li>之所以用<code>0</code>填充，是因为填充位置与卷积核相应神经元相乘的结果是<code>0</code>，可以降低因为填充对原始数据（此处为图片）产生的影响（此处有疑问，比如本人之前做过的一个用<code>0</code>填充的方式解决文本语义关系的课题，填充明显会对语义带来影响）。有待考究…</li>
</ul>
<p>什么时候用好：</p>
<ul>
<li>虽然 Andrej Karpathy 指出：实际应用中，<code>padding</code>的效果会比不<code>padding</code>的效果更好。不过实际应用中还是要根据自己的需要来设置，具体根据什么指标，正在考究…</li>
</ul>
</li>
<li><p>一维卷积的用处：改变深度（也就是视频中指出的数据的<code>depth</code>维度），但是并没有对特征在空间（也就是<code>width</code>和<code>height</code>方向上的特征）上进行merge。</p>
</li>
<li><p>一个层的输出深度可以很大，比如<code>6x6x512</code>，这不会有什么影响。</p>
</li>
<li><p><code>Pooling</code>会跌掉一些信息。</p>
</li>
<li><p>45分钟处没看懂。</p>
</li>
<li><p>不再使用<code>normalization layer</code>，因为这对网络没有 improvement。</p>
</li>
<li><p><code>fc 7 layer</code> 指输出结果前的最后一个全连接层，这个说法来自<code>AlexNet</code>。</p>
</li>
<li><p><code>Inception Module</code>来自<code>GoogleNet</code>。</p>
</li>
<li><p>普通的<code>CNN</code>指通过 evil 的方式增加网络的深度，可能不会改善效果（甚至恶化），但<code>ResNet</code>可以使结果更好（视频1:07:00处）</p>
</li>
</ol>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><strong>参考资料</strong></h3><ol>
<li><a href="http://xrds.acm.org/blog/2016/06/convolutional-neural-networks-cnns-illustrated-explanation/" target="_blank" rel="noopener">Convolutional Neural Networks (CNNs): An Illustrated Explanation - XRDSXRDS</a></li>
</ol>
<h2 id="Lecture-8"><a href="#Lecture-8" class="headerlink" title="Lecture 8"></a><strong>Lecture 8</strong></h2><h3 id="Image-Detection"><a href="#Image-Detection" class="headerlink" title="Image Detection"></a><strong>Image Detection</strong></h3><ol>
<li><p>Localization as regression</p>
<p> 把<code>Localization</code>当作<code>Regression</code>任务，在训练时只是把 classification 网络的最后几层的全连接层改一下：输出不再是<code>class score</code>，而是<code>box coordinate</code>；<code>loss</code>不再是<code>softmax</code>或其它classification任务的<code>loss</code>，而是<code>L2 loss</code>；test time 既进行<code>classification</code>，也进行<code>localization</code>。</p>
</li>
<li><p>Sliding Window</p>
<p> Idea：在图片上的多个 positions 做多次，然后把这些不同 positions 的结果 aggregate 起来。</p>
</li>
<li><p>2 分钟处：back propagation whole net是什么意思？</p>
</li>
</ol>
<h3 id="Image-Detection-1"><a href="#Image-Detection-1" class="headerlink" title="Image Detection"></a><strong>Image Detection</strong></h3><ol>
<li><p>因为图片中 object 的数量（不是种类）不确定，所以不能用<code>Regression/Localization</code>的方式解决。用<font color='red'>classification</font>的方式解决，输入为图片的不同区域。不过，<code>window size</code>要通过试的方式，测试所有可能的情况，所以计算量非常大。</p>
<p> 解决办法就是不试所有的情况，而是猜——<code>Region Proposal</code>。可能不够准确，也不关心每个区域的 object 的 class（类别），但是很快。最常用的方法是：<code>Selective Search</code>。</p>
</li>
<li><p>Selective Search</p>
<p> Idea：从某个 pixel 开始，把与它具有 similar color and texture 的 adjacent pixels 都 merge 起来 ——&gt; connected blob-like regions（如果接着把这些 regions 各自 merge up 起来就可以得到 bigger bloby parts/regions ）——&gt; different scales to different size detecting box——&gt; a whole bunch of boxs（详细可以见31分钟处）。</p>
</li>
<li><p><code>Region Proposal</code> + <code>CNN</code> ——&gt; <code>R-CNN</code></p>
<p> 使用 AlexNet，注意需要对网络进行 fine tune，因为数据集不同</p>
</li>
<li><p>Objection Detection Evaluation：<code>mPA</code></p>
<p> 使用更好的网络能够帮助进行 detection 任务的效果。</p>
</li>
<li><p><code>Fast R-CNN</code></p>
<p> 具体可见视频和slides。</p>
<p> Problem：在 test time 没有进行<code>Region Proposal</code>。<br> Solution：<code>Faster R-CNN</code></p>
</li>
<li><p><code>Faster R-CNN</code></p>
</li>
</ol>

      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/Computer-Vision/">Computer Vision</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/Deep-Learning/">Deep Learning</a>, <a href="/tags/CS231n/">CS231n</a>, <a href="/tags/CNN/">CNN</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">Comments</h1>

  
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript>
  </div>
  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:watsonyanghx.github.io">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">Categories</h3>
  <ul class="entry">
  
    <li><a href="/categories/Algorithm/">Algorithm</a><small>2</small></li>
  
    <li><a href="/categories/Computer-Vision/">Computer Vision</a><small>3</small></li>
  
    <li><a href="/categories/Deep-Learning/">Deep Learning</a><small>3</small></li>
  
    <li><a href="/categories/Interview/">Interview</a><small>1</small></li>
  
    <li><a href="/categories/Machine-Learning/">Machine Learning</a><small>8</small></li>
  
    <li><a href="/categories/Deep-Learning/Machine-Learning/">Machine Learning</a><small>1</small></li>
  
    <li><a href="/categories/NLP/">NLP</a><small>1</small></li>
  
    <li><a href="/categories/OJ/">OJ</a><small>48</small></li>
  
    <li><a href="/categories/Paper/">Paper</a><small>5</small></li>
  
    <li><a href="/categories/Reinforcement-Learning/">Reinforcement Learning</a><small>1</small></li>
  
    <li><a href="/categories/Technique-Summaries/">Technique Summaries</a><small>2</small></li>
  
    <li><a href="/categories/Tools/">Tools</a><small>1</small></li>
  
    <li><a href="/categories/WhatEver/">WhatEver</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">Tag Cloud</h3>
  <div class="entry">
    <a href="/tags/Algorithm/" style="font-size: 18.18px;">Algorithm</a> <a href="/tags/BFS/" style="font-size: 11.82px;">BFS</a> <a href="/tags/Backtracking/" style="font-size: 12.73px;">Backtracking</a> <a href="/tags/Binary-Tree/" style="font-size: 14.55px;">Binary Tree</a> <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/CNN/" style="font-size: 15.45px;">CNN</a> <a href="/tags/CS231n/" style="font-size: 11.82px;">CS231n</a> <a href="/tags/Combinatorial-number/" style="font-size: 10.91px;">Combinatorial number</a> <a href="/tags/DFS/" style="font-size: 14.55px;">DFS</a> <a href="/tags/DP/" style="font-size: 19.09px;">DP</a> <a href="/tags/Data-structure/" style="font-size: 10.91px;">Data structure</a> <a href="/tags/DeconvNet/" style="font-size: 10px;">DeconvNet</a> <a href="/tags/Deep-Learning/" style="font-size: 17.27px;">Deep Learning</a> <a href="/tags/Disjoint-Set/" style="font-size: 11.82px;">Disjoint Set</a> <a href="/tags/Divide-and-Conquer/" style="font-size: 13.64px;">Divide and Conquer</a> <a href="/tags/GAN/" style="font-size: 10.91px;">GAN</a> <a href="/tags/Graph/" style="font-size: 13.64px;">Graph</a> <a href="/tags/Greedy/" style="font-size: 11.82px;">Greedy</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/HihoCoder/" style="font-size: 16.36px;">HihoCoder</a> <a href="/tags/IPv6/" style="font-size: 10px;">IPv6</a> <a href="/tags/LintCode/" style="font-size: 20px;">LintCode</a> <a href="/tags/Machine-Learning/" style="font-size: 10.91px;">Machine Learning</a> <a href="/tags/Matrix/" style="font-size: 10px;">Matrix</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/Normalization/" style="font-size: 10px;">Normalization</a> <a href="/tags/Notes/" style="font-size: 10px;">Notes</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/POJ/" style="font-size: 10.91px;">POJ</a> <a href="/tags/Permutation/" style="font-size: 10px;">Permutation</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Queue/" style="font-size: 10.91px;">Queue</a> <a href="/tags/RL/" style="font-size: 10px;">RL</a> <a href="/tags/Recursion/" style="font-size: 12.73px;">Recursion</a> <a href="/tags/ResNet/" style="font-size: 10px;">ResNet</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/String/" style="font-size: 11.82px;">String</a> <a href="/tags/VPS/" style="font-size: 10px;">VPS</a> <a href="/tags/WhatEver/" style="font-size: 10px;">WhatEver</a>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2020 Watson Yang
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'light-disqus';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<div id="totop" style="position:fixed;bottom:35px;right:20px;cursor: pointer;">
  <a title="返回顶部"><i class="fa fa-angle-double-up fa-3x" aria-hidden="true"></i></a>
</div>
<script src="/js/totop.js"></script>

</body>
</html>
