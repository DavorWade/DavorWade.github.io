<!DOCTYPE HTML>
<html>

<head>
  <meta name="google-site-verification" content="6-Grm86DHfS67XSHMuvfO8cIcQcOWPpjGvOBMxbA3Fo" />
  <meta charset="utf-8">
  
  <title>CS231n Assignment | WatsonYang&#39;s Blog</title>
  
  <meta name="author" content="Watson Yang">
  
  <meta name="description" content="My secret private space.">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:title" content="CS231n Assignment" />
  <meta property="og:site_name" content="WatsonYang&#39;s Blog" />

  
  <meta property="og:image" content="" />
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml"
    title="WatsonYang&#39;s Blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  


  <a href="https://github.com/watsonyanghx" target="_blank">
    <img style="position: absolute; top: 0; left: 0; border: 0;"
      src="https://s3.amazonaws.com/github/ribbons/forkme_left_gray_6d6d6d.png" alt="Fork me on GitHub">
  </a>
  <script src="https://use.fontawesome.com/4eb261e456.js"></script>

  <script>
    MathJax = {
      tex: {
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ]
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>
<meta name="generator" content="Hexo 4.2.0"></head>

<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">WatsonYang&#39;s Blog</a></h1>
  <h2><a href="/">Enrich yourself.</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/about">About</a></li>
    

    <li> <a href="/atom.xml">RSS</a> </li>
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2017-01-17T17:35:56.000Z"><a href="/2017/01/18/CS231n-Assignment/">2017-01-18</a></time>
      
      
  
    <h1 class="title">CS231n Assignment</h1>
  

    </header>
    <div class="entry">
      
        <p><code>CS231n</code>课程作业，记录自己弄懂和没弄懂的地方。第一个作业难度不大，感觉都是在练习<code>numpy</code>的使用（相关函数的总结可以看 <a href="https://watsonyanghx.github.io/2017/01/19/Frequently-used-Numpy-functions/">Frequently-used-Numpy-functions</a>），特别是矩阵运算（广播等）。</p>
<p>因为在代码中相应部分都有注释（基本就相当于在代码里直接进行讲解了），感觉这里没有必要写个博客详细讲解，所以这里只是随便记录一些感觉还算重要的东西，以便日后复习。</p>
<p>具体代码可以见<code>github</code>的 <a href="https://github.com/watsonyanghx/CS231n" target="_blank" rel="noopener">CS231n</a>。</p>
<h2 id="CS231n-Assignment-1"><a href="#CS231n-Assignment-1" class="headerlink" title="CS231n Assignment 1"></a>CS231n Assignment 1</h2><h3 id="Q1-k-Nearest-Neighbor-classifier"><a href="#Q1-k-Nearest-Neighbor-classifier" class="headerlink" title="Q1: k-Nearest Neighbor classifier"></a>Q1: k-Nearest Neighbor classifier</h3><ol>
<li><p>与大多数分类器一样，<code>KNN</code>分为两个步骤：<code>train</code>和<code>predict</code>。但不同的是，严格来说<code>KNN</code>没有<code>train</code>的过程（<code>KNN</code>的<code>train</code>过程就是“记住”所有的数据），在实际代码中通常按照下面的做（在 <a href="https://github.com/watsonyanghx/CS231n/blob/master/assignment1/knn.ipynb" target="_blank" rel="noopener">knn.ipynb</a> 的第<code>6</code>个<code>cell</code>中也有提到）：</p>
 <a id="more"></a>

<ul>
<li><p><code>train</code>过程：载入所有的训练数据和测试数据，由于需要全部保存在内存中（比较消耗内存），所以称为“记住”。</p>
</li>
<li><p><code>predict</code>过程：首先，计算<font color="red">每个</font>测试数据与所有训练数据的<strong>距离矩阵</strong>；然后，返回每个测试数据对应<strong>距离矩阵</strong>中前<code>k</code>小的训练数据的<code>label</code>（有点绕，可以看代码）；最后，把这<code>k</code>个<code>label</code>中出现次数最多的<code>label</code>，作为这个测试数据的<code>label</code>。</p>
</li>
</ul>
</li>
<li><p>上面的<code>predict</code>过程适用于<strong>分类任务</strong>，如果是<strong>回归</strong>，在得出前<code>k</code>小的<font color="red">训练数据</font>（这里不再是<code>label</code>，直接就是训练数据）后，进行求平均或者其它方式求得这个测试数据的回归（预测）值。</p>
</li>
<li><p>可以用<code>cross-validation</code>选择合适的<code>k</code>值，具体做法可以参考 <a href="https://github.com/watsonyanghx/CS231n/blob/master/assignment1/knn.ipynb" target="_blank" rel="noopener">knn.ipynb</a> 的第<code>14</code>个<code>cell</code>。</p>
</li>
<li><p>注意<code>validation set</code>与<code>cross validation</code>是不同的。前者是<strong>固定</strong>一个<code>dataset</code>，一般是整个<code>training dataset</code>的<code>20%</code>（这个比例根据算法中有多少<code>hyperparameter</code>，以及这些<code>hyperparameter</code>对于算法的预期影响来决定）；后者是为了解决数据集太小的问题，一般是通过把数据集平均分的方法，只留一个做<code>validation dataset</code>，其它的做<code>training dataset</code>。</p>
</li>
<li><p><code>hyperparameter</code>的确定是通过<code>validation dataset</code><strong>搜索</strong>得到的，当数量较少时就使用<code>cross validation</code></p>
</li>
</ol>
<h3 id="Q2-Training-a-Support-Vector-Machine"><a href="#Q2-Training-a-Support-Vector-Machine" class="headerlink" title="Q2: Training a Support Vector Machine"></a>Q2: Training a Support Vector Machine</h3><ol>
<li><p>思路比较简单，同样分为下面两个过程。</p>
<ul>
<li><p><code>train</code>过程：计算<code>loss</code>和<code>gradient</code>，根据<code>gradient</code>更新权重<code>W</code>。</p>
</li>
<li><p><code>predict</code>过程：用训练好的权重<code>W</code>对测试数据进行预测。</p>
</li>
</ul>
</li>
<li><p>所有的数据集都要减去<code>X_train</code>的图片的平均值（可见 <a href="https://github.com/watsonyanghx/CS231n/blob/master/assignment1/svm.ipynb" target="_blank" rel="noopener">svm.ipynb</a>的第<code>7</code>个<code>cell</code>）?</p>
</li>
</ol>
<p><strong>注意:</strong></p>
<ul>
<li><p>要注意是要减去<code>X_train</code>的平均值</p>
</li>
<li><p>这里减去的是<code>channel</code>的平均值：<code>np.mean(X_train, axis=0)</code>，而<strong>不是</strong>每个图片减去各自的平均值（<code>VGGNet</code>中也是这么做的)。</p>
</li>
<li><p><code>AlexNet</code>中减去的是各自的平均值：<code>np.mean(X_train, axis=1)</code>。</p>
</li>
<li><p>可见 Lecture 5 的35分钟处。</p>
</li>
</ul>
<h3 id="Q3-Implement-a-Softmax-classifier"><a href="#Q3-Implement-a-Softmax-classifier" class="headerlink" title="Q3: Implement a Softmax classifier"></a>Q3: Implement a Softmax classifier</h3><ol>
<li>同上面，两者只是<code>loss</code>和<code>gradient</code>计算不一样。</li>
</ol>
<h3 id="Q4-Two-Layer-Neural-Network"><a href="#Q4-Two-Layer-Neural-Network" class="headerlink" title="Q4: Two-Layer Neural Network"></a>Q4: Two-Layer Neural Network</h3><ol>
<li><p><code>gradient</code>的计算没弄懂。</p>
</li>
<li><p>取<code>batch</code>进行训练:</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">indices = np.random.choice(num_train, batch_size)</span><br><span class="line">X_batch = X[indices]</span><br><span class="line">y_batch = y[indices]</span><br></pre></td></tr></table></figure>


<h3 id="Q5-Higher-Level-Representations-Image-Features"><a href="#Q5-Higher-Level-Representations-Image-Features" class="headerlink" title="Q5: Higher Level Representations: Image Features"></a>Q5: Higher Level Representations: Image Features</h3><ol>
<li>没有太多代码要写，就是说明<code>feature extraction</code>对提高模型的性能能起到很好的作用。</li>
</ol>
<h2 id="CS231n-Assignment-2"><a href="#CS231n-Assignment-2" class="headerlink" title="CS231n Assignment 2"></a>CS231n Assignment 2</h2><h3 id="Q1-Fully-connected-Neural-Network"><a href="#Q1-Fully-connected-Neural-Network" class="headerlink" title="Q1: Fully-connected Neural Network"></a>Q1: Fully-connected Neural Network</h3><ol>
<li>的代码不是很好，耦合度比较高，这里对其进行解耦，把代码模块化。整个作业的代码都很规范，可以直接拿来用，也很值得学习。</li>
</ol>
<h3 id="Q2-Batch-Normalization"><a href="#Q2-Batch-Normalization" class="headerlink" title="Q2: Batch Normalization"></a>Q2: Batch Normalization</h3><ol>
<li><a href="https://github.com/watsonyanghx/CS231n/blob/master/assignment2/BatchNormalization.ipynb" target="_blank" rel="noopener">BatchNormalization.ipynb</a> 的最后一个问题怎么回答？</li>
</ol>
<h3 id="Q3-Dropout"><a href="#Q3-Dropout" class="headerlink" title="Q3: Dropout"></a>Q3: Dropout</h3><ol>
<li><p><code>BatchNormalization</code>与<code>Dropout</code>在<code>train</code>与<code>test</code>的过程中都是不同的。</p>
</li>
<li><p><code>BatchNormalization</code>在<code>ReLU</code>的前面，<code>Dropout</code>在<code>ReLU</code>的后面：<code>BatchNormalization --&gt; ReLU --&gt; Dropout</code></p>
</li>
<li><p>Dropout</p>
<ul>
<li>让激活值（就是<code>WX + b</code>的结果）以一定的概率随机失活（就是设置成<code>0</code>），目的是降低不同神经元之间的联系，从而减轻<code>overfitting</code>现象的程度。</li>
</ul>
</li>
<li><p>Maxout</p>
<p> <a href="https://tangxman.github.io/2015/12/26/maxout/" target="_blank" rel="noopener">Maxout 简单理解</a></p>
</li>
</ol>
<h3 id="Q4-ConvNet-on-CIFAR-10"><a href="#Q4-ConvNet-on-CIFAR-10" class="headerlink" title="Q4: ConvNet on CIFAR-10"></a>Q4: ConvNet on CIFAR-10</h3><h2 id="CS231n-Assignment-3"><a href="#CS231n-Assignment-3" class="headerlink" title="CS231n Assignment 3"></a>CS231n Assignment 3</h2><h3 id="Q1-Image-Captioning-with-Vanilla-RNNs"><a href="#Q1-Image-Captioning-with-Vanilla-RNNs" class="headerlink" title="Q1: Image Captioning with Vanilla RNNs"></a>Q1: Image Captioning with Vanilla RNNs</h3><ol>
<li><p><code>rnn_forward(x, h0, wx, wh, b)</code>中batch为什么是<code>(N, T, D)</code>？</p>
<p> 因为取<code>N</code>个example训练，每个都有<code>T</code>个长度的时间维度，每个维度都是<code>D</code>。比如取N个句子，每个句子都有<code>T</code>个单词（不够长度的填充），每个单词的word embedding维度都是<code>D</code>。</p>
</li>
<li><p>为什么<code>rnn_forward(x, h0, wx, wh, b)</code>的计算方式与<code>temporal_affine_forward(x, w, b)</code>的不一样，后者可以<code>reshape</code>后相乘？</p>
</li>
</ol>
<h3 id="Q2-Image-Captioning-with-LSTMs"><a href="#Q2-Image-Captioning-with-LSTMs" class="headerlink" title="Q2: Image Captioning with LSTMs"></a>Q2: Image Captioning with LSTMs</h3><h3 id="Q3-Image-Gradients-Saliency-maps-and-Fooling-Images"><a href="#Q3-Image-Gradients-Saliency-maps-and-Fooling-Images" class="headerlink" title="Q3: Image Gradients: Saliency maps and Fooling Images"></a>Q3: Image Gradients: Saliency maps and Fooling Images</h3><h3 id="Q4-Image-Generation-Classes-Inversion-DeepDream"><a href="#Q4-Image-Generation-Classes-Inversion-DeepDream" class="headerlink" title="Q4: Image Generation: Classes, Inversion, DeepDream"></a>Q4: Image Generation: Classes, Inversion, DeepDream</h3>
      
    </div>
    <footer>
      
        
  
  <div class="categories">
    <a href="/categories/Computer-Vision/">Computer Vision</a>
  </div>

        
  
  <div class="tags">
    <a href="/tags/Deep-Learning/">Deep Learning</a>, <a href="/tags/CS231n/">CS231n</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">
  <h1 class="title">Comments</h1>

  
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript>
  </div>
  
</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:watsonyanghx.github.io">
  </form>
</div>

  
<div class="widget tag">
  <h3 class="title">Categories</h3>
  <ul class="entry">
  
    <li><a href="/categories/Algorithm/">Algorithm</a><small>2</small></li>
  
    <li><a href="/categories/Computer-Vision/">Computer Vision</a><small>3</small></li>
  
    <li><a href="/categories/Deep-Learning/">Deep Learning</a><small>3</small></li>
  
    <li><a href="/categories/Interview/">Interview</a><small>1</small></li>
  
    <li><a href="/categories/Machine-Learning/">Machine Learning</a><small>8</small></li>
  
    <li><a href="/categories/Deep-Learning/Machine-Learning/">Machine Learning</a><small>1</small></li>
  
    <li><a href="/categories/NLP/">NLP</a><small>1</small></li>
  
    <li><a href="/categories/OJ/">OJ</a><small>48</small></li>
  
    <li><a href="/categories/Paper/">Paper</a><small>5</small></li>
  
    <li><a href="/categories/Reinforcement-Learning/">Reinforcement Learning</a><small>1</small></li>
  
    <li><a href="/categories/Technique-Summaries/">Technique Summaries</a><small>2</small></li>
  
    <li><a href="/categories/Tools/">Tools</a><small>1</small></li>
  
    <li><a href="/categories/WhatEver/">WhatEver</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">Tag Cloud</h3>
  <div class="entry">
    <a href="/tags/Algorithm/" style="font-size: 18.18px;">Algorithm</a> <a href="/tags/BFS/" style="font-size: 11.82px;">BFS</a> <a href="/tags/Backtracking/" style="font-size: 12.73px;">Backtracking</a> <a href="/tags/Binary-Tree/" style="font-size: 14.55px;">Binary Tree</a> <a href="/tags/C/" style="font-size: 10px;">C++</a> <a href="/tags/CNN/" style="font-size: 15.45px;">CNN</a> <a href="/tags/CS231n/" style="font-size: 11.82px;">CS231n</a> <a href="/tags/Combinatorial-number/" style="font-size: 10.91px;">Combinatorial number</a> <a href="/tags/DFS/" style="font-size: 14.55px;">DFS</a> <a href="/tags/DP/" style="font-size: 19.09px;">DP</a> <a href="/tags/Data-structure/" style="font-size: 10.91px;">Data structure</a> <a href="/tags/DeconvNet/" style="font-size: 10px;">DeconvNet</a> <a href="/tags/Deep-Learning/" style="font-size: 17.27px;">Deep Learning</a> <a href="/tags/Disjoint-Set/" style="font-size: 11.82px;">Disjoint Set</a> <a href="/tags/Divide-and-Conquer/" style="font-size: 13.64px;">Divide and Conquer</a> <a href="/tags/GAN/" style="font-size: 10.91px;">GAN</a> <a href="/tags/Graph/" style="font-size: 13.64px;">Graph</a> <a href="/tags/Greedy/" style="font-size: 11.82px;">Greedy</a> <a href="/tags/Hexo/" style="font-size: 10px;">Hexo</a> <a href="/tags/HihoCoder/" style="font-size: 16.36px;">HihoCoder</a> <a href="/tags/IPv6/" style="font-size: 10px;">IPv6</a> <a href="/tags/LintCode/" style="font-size: 20px;">LintCode</a> <a href="/tags/Machine-Learning/" style="font-size: 10.91px;">Machine Learning</a> <a href="/tags/Matrix/" style="font-size: 10px;">Matrix</a> <a href="/tags/NLP/" style="font-size: 10px;">NLP</a> <a href="/tags/Normalization/" style="font-size: 10px;">Normalization</a> <a href="/tags/Notes/" style="font-size: 10px;">Notes</a> <a href="/tags/Numpy/" style="font-size: 10px;">Numpy</a> <a href="/tags/POJ/" style="font-size: 10.91px;">POJ</a> <a href="/tags/Permutation/" style="font-size: 10px;">Permutation</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Queue/" style="font-size: 10.91px;">Queue</a> <a href="/tags/RL/" style="font-size: 10px;">RL</a> <a href="/tags/Recursion/" style="font-size: 12.73px;">Recursion</a> <a href="/tags/ResNet/" style="font-size: 10px;">ResNet</a> <a href="/tags/Shadowsocks/" style="font-size: 10px;">Shadowsocks</a> <a href="/tags/String/" style="font-size: 11.82px;">String</a> <a href="/tags/VPS/" style="font-size: 10px;">VPS</a> <a href="/tags/WhatEver/" style="font-size: 10px;">WhatEver</a>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2020 Watson Yang
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'light-disqus';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<div id="totop" style="position:fixed;bottom:35px;right:20px;cursor: pointer;">
  <a title="返回顶部"><i class="fa fa-angle-double-up fa-3x" aria-hidden="true"></i></a>
</div>
<script src="/js/totop.js"></script>

</body>
</html>
